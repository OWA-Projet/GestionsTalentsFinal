{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11042941,"sourceType":"datasetVersion","datasetId":6878875},{"sourceId":11095327,"sourceType":"datasetVersion","datasetId":6916517}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pdfplumber\n\npdf_path = \"/kaggle/input/cvvvvvvvvvv/cvwail.pdf\"\nwith pdfplumber.open(pdf_path) as pdf:\n    text = \"\\n\".join([page.extract_text() for page in pdf.pages if page.extract_text()])\nprint(text)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T18:21:46.734525Z","iopub.execute_input":"2025-03-15T18:21:46.734910Z","iopub.status.idle":"2025-03-15T18:21:47.253302Z","shell.execute_reply.started":"2025-03-15T18:21:46.734863Z","shell.execute_reply":"2025-03-15T18:21:47.252273Z"}},"outputs":[{"name":"stdout","text":"WAIL BENHARRATS\nFutur ing√©nieur en informatique option\nMIAGE √† l‚ÄôEMSI √† la recherche d‚Äôun stage\nPFE √† partir du mois de mars\nformation Academique\nOctobre 2024\nCONTACT\nMaster MIAGE IA2 Universit√© C√¥te d‚ÄôAzure\n0661990707 2020-2025\nDipl√¥me d'ing√©nieur en informatique et r√©seaux\nbenharatswail@gmail.com\n√âcole Marocaine des Sciences de l'Ing√©nieur\nRabat, Maroc\n2019-2020\nWail Benharrats Bac Sciences Physiques\nCertifications Lyc√©e scientifique Tour Hassan\nExp√©rience professionnelle\nOracle Database Administration I\n(2024)\n07/2023-08/2023 - Stage de fin d‚Äôann√©e\ning√©nierie logicielle (2023)\nMod√©lisation des syst√®mes Entreprise ECONOCOM\nlogiciels a l‚Äôaide de l‚ÄôUML\nApplication Web de Gestion des Cong√©s\nPython for everybody - University of\nMichigan (2023) Conception et d√©veloppement complet d'une application web de\ngestion des cong√©s utilisant FastAPI, un framework Python pour\nReact Basics (2023)\nles API web.\nUnix System Basics (2023)\nD√©veloppement des fonctionnalit√©s de gestion des demandes\nde cong√©s, de suivi des cong√©s disponibles, et de g√©n√©ration de\nProjets academiques rapports pour les employ√©s et les managers.\nProjet Fin d‚Äôann√©e de la 4eme ann√©e 07/2024-08/2024 - Stage de de fin d‚Äôann√©e\nR√©alisation d‚Äôune application web\nEntreprise DIRHAM EXPRESS\nd‚Äôarchivage en utilisant Spring Boot\nApplication Web de Gestion des employ√©s et stocks\nProjet Fin d‚Äôann√©e de la 3eme ann√©e\nR√©alisation d‚Äôune application web de Conception et d√©veloppement complet d'une application web de\ngestion d'√©cole en utilisant Django gestion des employ√©s et stocks en utilisant Django et en int√©grant\ndans le projet la reconnaissance faciale et les d√©tection des objets .\nLangues Connaissances techniques\nLangages de Programmation : C,C++, Java, Python, C#\nAnglais : niveau c1\nFrameworks : Django,Fast API,.NET,Spring Boot,JEE\nFran√ßais : niveau c1\nBases de Donn√©es : SQL, T-SQL, PL/SQL, MySQL Server,\nArabe : langue maternelle\nOracle\nOutils ETL : Talend Open Studio\nCentre d‚Äôint√©r√™ts\nBig Data : Hadoop MapReduce,Pig,Hive, Microsoft Azure\nSport\nConception et Mod√©lisation : Merise, UML\nSuivi des tendances technologiques\nD√©veloppement Mobile : Android Studio\nb√©n√©volat\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import re\n\n# Suppression des caract√®res sp√©ciaux et multiples espaces\ncleaned_text = re.sub(r'\\s+', ' ', text).strip()\nprint(cleaned_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T18:21:59.401361Z","iopub.execute_input":"2025-03-15T18:21:59.401792Z","iopub.status.idle":"2025-03-15T18:21:59.406824Z","shell.execute_reply.started":"2025-03-15T18:21:59.401765Z","shell.execute_reply":"2025-03-15T18:21:59.405721Z"}},"outputs":[{"name":"stdout","text":"WAIL BENHARRATS Futur ing√©nieur en informatique option MIAGE √† l‚ÄôEMSI √† la recherche d‚Äôun stage PFE √† partir du mois de mars formation Academique Octobre 2024 CONTACT Master MIAGE IA2 Universit√© C√¥te d‚ÄôAzure 0661990707 2020-2025 Dipl√¥me d'ing√©nieur en informatique et r√©seaux benharatswail@gmail.com √âcole Marocaine des Sciences de l'Ing√©nieur Rabat, Maroc 2019-2020 Wail Benharrats Bac Sciences Physiques Certifications Lyc√©e scientifique Tour Hassan Exp√©rience professionnelle Oracle Database Administration I (2024) 07/2023-08/2023 - Stage de fin d‚Äôann√©e ing√©nierie logicielle (2023) Mod√©lisation des syst√®mes Entreprise ECONOCOM logiciels a l‚Äôaide de l‚ÄôUML Application Web de Gestion des Cong√©s Python for everybody - University of Michigan (2023) Conception et d√©veloppement complet d'une application web de gestion des cong√©s utilisant FastAPI, un framework Python pour React Basics (2023) les API web. Unix System Basics (2023) D√©veloppement des fonctionnalit√©s de gestion des demandes de cong√©s, de suivi des cong√©s disponibles, et de g√©n√©ration de Projets academiques rapports pour les employ√©s et les managers. Projet Fin d‚Äôann√©e de la 4eme ann√©e 07/2024-08/2024 - Stage de de fin d‚Äôann√©e R√©alisation d‚Äôune application web Entreprise DIRHAM EXPRESS d‚Äôarchivage en utilisant Spring Boot Application Web de Gestion des employ√©s et stocks Projet Fin d‚Äôann√©e de la 3eme ann√©e R√©alisation d‚Äôune application web de Conception et d√©veloppement complet d'une application web de gestion d'√©cole en utilisant Django gestion des employ√©s et stocks en utilisant Django et en int√©grant dans le projet la reconnaissance faciale et les d√©tection des objets . Langues Connaissances techniques Langages de Programmation : C,C++, Java, Python, C# Anglais : niveau c1 Frameworks : Django,Fast API,.NET,Spring Boot,JEE Fran√ßais : niveau c1 Bases de Donn√©es : SQL, T-SQL, PL/SQL, MySQL Server, Arabe : langue maternelle Oracle Outils ETL : Talend Open Studio Centre d‚Äôint√©r√™ts Big Data : Hadoop MapReduce,Pig,Hive, Microsoft Azure Sport Conception et Mod√©lisation : Merise, UML Suivi des tendances technologiques D√©veloppement Mobile : Android Studio b√©n√©volat\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import spacy\n\n# Charger le mod√®le fran√ßais de spaCy\nnlp = spacy.load(\"fr_core_news_sm\")  \n\ndoc = nlp(cleaned_text)\nfor ent in doc.ents:\n    print(f\"{ent.label_}: {ent.text}\")  # Afficher les entit√©s reconnues\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T18:23:43.391945Z","iopub.execute_input":"2025-03-15T18:23:43.392306Z","iopub.status.idle":"2025-03-15T18:23:49.362687Z","shell.execute_reply.started":"2025-03-15T18:23:43.392277Z","shell.execute_reply":"2025-03-15T18:23:49.357523Z"}},"outputs":[{"name":"stdout","text":"MISC: WAIL BENHARRATS Futur\nORG: l‚ÄôEMSI\nMISC: PFE\nLOC: Dipl√¥me\nORG: √âcole Marocaine des Sciences de l'Ing√©nieur Rabat\nLOC: Maroc\nORG: Sciences Physiques\nMISC: Tour Hassan\nMISC: Entreprise\nMISC: ECONOCOM\nLOC: l‚Äô\nLOC: l‚Äô\nPER: Gestion des\nMISC: Python for everybody\nPER: Conception\nMISC: FastAPI\nMISC: Python\nPER: React Basics\nMISC: Unix System Basics\nLOC: Projets\nMISC: R√©alisation\nMISC: Entreprise DIRHAM EXPRESS d‚Äô\nPER: Spring\nMISC: Application Web\nPER: Gestion\nMISC: R√©alisation\nPER: Conception\nLOC: Django\nLOC: Django\nMISC: Langues Connaissances techniques Langages de Programmation :\nMISC: C++\nMISC: Java\nMISC: Python\nMISC: C#\nMISC: Anglais\nMISC: c1 Frameworks : Django\nPER: Fast API,\nMISC: NET\nMISC: Spring Boot\nMISC: JEE Fran√ßais\nORG: c1 Bases\nLOC: Donn√©es\nMISC: SQL\nMISC: T-SQL\nMISC: PL/SQL\nMISC: MySQL Server\nMISC: Arabe\nPER: Oracle Outils ETL\nPER: Hadoop MapReduce\nLOC: Pig\nMISC: Hive\nORG: Microsoft\nLOC: Mod√©lisation\nMISC: D√©veloppement Mobile\nMISC: Android Studio b√©n√©volat\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# D√©finition de regex pour identifier les sections sp√©cifiques\nlangues_pattern = r\"(Langues|Langage(s)? :?)(.*)\"\nformations_pattern = r\"(Formation(s)?|Dipl√¥me(s)? :?)(.*)\"\ncompetences_pattern = r\"(Comp√©tences|Technologies|Logiciels :?)(.*)\"\n\n# Recherche des correspondances dans le texte\nlangues = re.findall(langues_pattern, cleaned_text, re.IGNORECASE)\nformations = re.findall(formations_pattern, cleaned_text, re.IGNORECASE)\ncompetences = re.findall(competences_pattern, cleaned_text, re.IGNORECASE)\n\nprint(\"Langues:\", langues)\nprint(\"Formations:\", formations)\nprint(\"Comp√©tences:\", competences)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T18:25:15.216904Z","iopub.execute_input":"2025-03-15T18:25:15.217328Z","iopub.status.idle":"2025-03-15T18:25:15.226378Z","shell.execute_reply.started":"2025-03-15T18:25:15.217298Z","shell.execute_reply":"2025-03-15T18:25:15.225310Z"}},"outputs":[{"name":"stdout","text":"Langues: [('Langues', '', ' Connaissances techniques Langages de Programmation : C,C++, Java, Python, C# Anglais : niveau c1 Frameworks : Django,Fast API,.NET,Spring Boot,JEE Fran√ßais : niveau c1 Bases de Donn√©es : SQL, T-SQL, PL/SQL, MySQL Server, Arabe : langue maternelle Oracle Outils ETL : Talend Open Studio Centre d‚Äôint√©r√™ts Big Data : Hadoop MapReduce,Pig,Hive, Microsoft Azure Sport Conception et Mod√©lisation : Merise, UML Suivi des tendances technologiques D√©veloppement Mobile : Android Studio b√©n√©volat')]\nFormations: [('formation', '', '', \" Academique Octobre 2024 CONTACT Master MIAGE IA2 Universit√© C√¥te d‚ÄôAzure 0661990707 2020-2025 Dipl√¥me d'ing√©nieur en informatique et r√©seaux benharatswail@gmail.com √âcole Marocaine des Sciences de l'Ing√©nieur Rabat, Maroc 2019-2020 Wail Benharrats Bac Sciences Physiques Certifications Lyc√©e scientifique Tour Hassan Exp√©rience professionnelle Oracle Database Administration I (2024) 07/2023-08/2023 - Stage de fin d‚Äôann√©e ing√©nierie logicielle (2023) Mod√©lisation des syst√®mes Entreprise ECONOCOM logiciels a l‚Äôaide de l‚ÄôUML Application Web de Gestion des Cong√©s Python for everybody - University of Michigan (2023) Conception et d√©veloppement complet d'une application web de gestion des cong√©s utilisant FastAPI, un framework Python pour React Basics (2023) les API web. Unix System Basics (2023) D√©veloppement des fonctionnalit√©s de gestion des demandes de cong√©s, de suivi des cong√©s disponibles, et de g√©n√©ration de Projets academiques rapports pour les employ√©s et les managers. Projet Fin d‚Äôann√©e de la 4eme ann√©e 07/2024-08/2024 - Stage de de fin d‚Äôann√©e R√©alisation d‚Äôune application web Entreprise DIRHAM EXPRESS d‚Äôarchivage en utilisant Spring Boot Application Web de Gestion des employ√©s et stocks Projet Fin d‚Äôann√©e de la 3eme ann√©e R√©alisation d‚Äôune application web de Conception et d√©veloppement complet d'une application web de gestion d'√©cole en utilisant Django gestion des employ√©s et stocks en utilisant Django et en int√©grant dans le projet la reconnaissance faciale et les d√©tection des objets . Langues Connaissances techniques Langages de Programmation : C,C++, Java, Python, C# Anglais : niveau c1 Frameworks : Django,Fast API,.NET,Spring Boot,JEE Fran√ßais : niveau c1 Bases de Donn√©es : SQL, T-SQL, PL/SQL, MySQL Server, Arabe : langue maternelle Oracle Outils ETL : Talend Open Studio Centre d‚Äôint√©r√™ts Big Data : Hadoop MapReduce,Pig,Hive, Microsoft Azure Sport Conception et Mod√©lisation : Merise, UML Suivi des tendances technologiques D√©veloppement Mobile : Android Studio b√©n√©volat\")]\nComp√©tences: [('logiciels ', \"a l‚Äôaide de l‚ÄôUML Application Web de Gestion des Cong√©s Python for everybody - University of Michigan (2023) Conception et d√©veloppement complet d'une application web de gestion des cong√©s utilisant FastAPI, un framework Python pour React Basics (2023) les API web. Unix System Basics (2023) D√©veloppement des fonctionnalit√©s de gestion des demandes de cong√©s, de suivi des cong√©s disponibles, et de g√©n√©ration de Projets academiques rapports pour les employ√©s et les managers. Projet Fin d‚Äôann√©e de la 4eme ann√©e 07/2024-08/2024 - Stage de de fin d‚Äôann√©e R√©alisation d‚Äôune application web Entreprise DIRHAM EXPRESS d‚Äôarchivage en utilisant Spring Boot Application Web de Gestion des employ√©s et stocks Projet Fin d‚Äôann√©e de la 3eme ann√©e R√©alisation d‚Äôune application web de Conception et d√©veloppement complet d'une application web de gestion d'√©cole en utilisant Django gestion des employ√©s et stocks en utilisant Django et en int√©grant dans le projet la reconnaissance faciale et les d√©tection des objets . Langues Connaissances techniques Langages de Programmation : C,C++, Java, Python, C# Anglais : niveau c1 Frameworks : Django,Fast API,.NET,Spring Boot,JEE Fran√ßais : niveau c1 Bases de Donn√©es : SQL, T-SQL, PL/SQL, MySQL Server, Arabe : langue maternelle Oracle Outils ETL : Talend Open Studio Centre d‚Äôint√©r√™ts Big Data : Hadoop MapReduce,Pig,Hive, Microsoft Azure Sport Conception et Mod√©lisation : Merise, UML Suivi des tendances technologiques D√©veloppement Mobile : Android Studio b√©n√©volat\")]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import re\nimport spacy\nimport pandas as pd\nfrom PyPDF2 import PdfReader\nfrom pathlib import Path\n\n# Param√®tres √† modifier\ndossier_cv = \"/kaggle/input/cvvvvvvvvvvvvvvvvv\"  # <-- Changez ce chemin vers votre dossier contenant les CV au format PDF\n\n# Installation et chargement du mod√®le spaCy fran√ßais\ntry:\n    nlp = spacy.load(\"fr_core_news_md\")\nexcept:\n    print(\"Installation du mod√®le fran√ßais SpaCy...\")\n    import os\n    os.system(\"python -m spacy download fr_core_news_md\")\n    nlp = spacy.load(\"fr_core_news_md\")\n\n# D√©finition des mots-cl√©s et patterns\nsection_patterns = {\n    'formations': r'formations?|√©ducations?|dipl√¥mes?|cursus|√©tudes',\n    'comp√©tences': r'comp√©tences?|savoir.faire|expertises?|qualifications|technologies|outils|langages',\n    'experiences': r'exp√©riences?|parcours|postes?|emplois?',\n    'langues': r'langues?|linguistiques?',\n}\n\neducation_keywords = [\n    'bac', 'licence', 'master', 'doctorat', 'dipl√¥me', 'universit√©',\n    '√©cole', 'institut', 'ing√©nieur', 'formation', 'certificat'\n]\n\ntech_skills = [\n    'python', 'java', 'c++', 'javascript', 'html', 'css', 'sql', 'nosql',\n    'machine learning', 'deep learning', 'nlp', 'tensorflow', 'pytorch',\n    'scikit-learn', 'pandas', 'numpy', 'data mining', 'visualisation',\n    'cloud', 'aws', 'azure', 'gcp', 'devops', 'ci/cd', 'docker', 'kubernetes',\n    'git', 'agile', 'scrum', 'jira', 'confluence'\n]\n\n# Liste des fichiers PDF dans le dossier\ndossier = Path(dossier_cv)\npdf_files = list(dossier.glob(\"*.pdf\"))\nprint(f\"Traitement de {len(pdf_files)} fichiers PDF...\")\n\n# Liste pour stocker les r√©sultats\nresultats = []\n\n# Traitement de chaque fichier PDF\nfor pdf_file in pdf_files:\n    print(f\"Analyse de: {pdf_file.name}\")\n    \n    # Extraction du texte\n    try:\n        reader = PdfReader(pdf_file)\n        texte = \"\"\n        for page in reader.pages:\n            texte += page.extract_text() + \"\\n\"\n    except Exception as e:\n        print(f\"Erreur lors de l'extraction du texte PDF: {e}\")\n        continue\n    \n    # Pr√©traitement du texte\n    texte = re.sub(r'\\s+', ' ', texte)  # Normaliser les espaces\n    texte = re.sub(r'[^\\w\\s.,;:()\\/\\-\\'\\\"]+', ' ', texte)  # Supprimer caract√®res sp√©ciaux\n    texte = texte.strip()\n    \n    # Identification des sections\n    sections = {}\n    lignes = texte.split('\\n')\n    section_courante = 'unknown'\n    \n    for ligne in lignes:\n        ligne_lower = ligne.lower()\n        \n        # V√©rifier si cette ligne correspond √† un titre de section\n        for section, pattern in section_patterns.items():\n            if re.search(pattern, ligne_lower):\n                section_courante = section\n                sections[section_courante] = []\n                break\n        \n        # Ajouter la ligne √† la section courante\n        if section_courante in sections:\n            sections[section_courante].append(ligne)\n    \n    # Texte pour chaque section\n    formation_text = '\\n'.join(sections.get('formations', []))\n    competences_text = '\\n'.join(sections.get('comp√©tences', []))\n    langues_text = '\\n'.join(sections.get('langues', []))\n    \n    # Si les sections n'ont pas √©t√© identifi√©es, utiliser tout le texte\n    if not formation_text:\n        formation_text = texte\n    if not competences_text:\n        competences_text = texte\n    if not langues_text:\n        langues_text = texte\n    \n    # Extraction des formations\n    doc_formation = nlp(formation_text)\n    formations = []\n    \n    for sent in doc_formation.sents:\n        sent_text = sent.text.lower()\n        is_education = any(keyword in sent_text for keyword in education_keywords)\n        \n        if is_education:\n            # Extraire les dates\n            dates = re.findall(r'\\b(19|20)\\d{2}\\b', sent.text)\n            \n            # Extraire les entit√©s nomm√©es (√©coles, universit√©s)\n            org_names = [ent.text for ent in sent.ents if ent.label_ in [\"ORG\", \"LOC\"]]\n            \n            formations.append(sent.text.strip())\n    \n    # Extraction des comp√©tences techniques\n    comp_text_lower = competences_text.lower()\n    competences_tech = [skill for skill in tech_skills if re.search(r'\\b' + re.escape(skill) + r'\\b', comp_text_lower)]\n    \n    # Extraction d'autres comp√©tences potentielles\n    doc_comp = nlp(competences_text)\n    autres_comp = []\n    for token in doc_comp:\n        if token.pos_ in [\"NOUN\", \"PROPN\", \"ADJ\"] and len(token.text) > 3:\n            # Exclure les mots communs\n            if token.text.lower() not in [\"ann√©e\", \"exp√©rience\", \"poste\", \"travail\", \"projet\"]:\n                autres_comp.append(token.text)\n    \n    # D√©duplication et nettoyage des comp√©tences\n    autres_comp = list(set(autres_comp))[:15]  # Limiter pour √©viter le bruit\n    \n    # Extraction des langues\n    langues = [\"fran√ßais\", \"anglais\", \"espagnol\", \"allemand\", \"italien\", \"chinois\", \"arabe\", \"russe\", \"portugais\", \"japonais\"]\n    niveaux = [\"courant\", \"bilingue\", \"natif\", \"professionnel\", \"interm√©diaire\", \"d√©butant\", \"scolaire\", \"avanc√©\", \"b1\", \"b2\", \"c1\", \"c2\", \"a1\", \"a2\"]\n    \n    langues_detectees = {}\n    for langue in langues:\n        # Chercher la langue mentionn√©e avec son niveau potentiel\n        pattern = r'\\b' + langue + r'\\b.*?(' + '|'.join(niveaux) + r')\\b|(' + '|'.join(niveaux) + r')\\b.*?\\b' + langue + r'\\b'\n        match = re.search(pattern, langues_text.lower())\n        if match:\n            for niveau in niveaux:\n                if niveau in match.group(0):\n                    langues_detectees[langue] = niveau\n                    break\n        elif re.search(r'\\b' + langue + r'\\b', langues_text.lower()):\n            langues_detectees[langue] = \"mentionn√©\"\n    \n    # Pr√©paration des r√©sultats pour ce CV\n    resultats.append({\n        \"fichier\": pdf_file.name,\n        \"formations\": \", \".join(formations),\n        \"comp√©tences_techniques\": \", \".join(competences_tech),\n        \"autres_comp√©tences\": \", \".join(autres_comp),\n        \"langues\": \", \".join([f\"{langue} ({niveau})\" for langue, niveau in langues_detectees.items()])\n    })\n\n# Cr√©ation et affichage du DataFrame\nif resultats:\n    df = pd.DataFrame(resultats)\n    \n    # Configuration pour un meilleur affichage\n    pd.set_option('display.max_columns', None)\n    pd.set_option('display.width', None)\n    pd.set_option('display.max_colwidth', None)\n    \n    # Affichage du DataFrame\n    print(\"\\n========== R√âSULTATS DE L'ANALYSE ==========\\n\")\n    print(df)\nelse:\n    print(\"Aucun r√©sultat n'a √©t√© extrait.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T01:14:05.722121Z","iopub.execute_input":"2025-03-20T01:14:05.722530Z","iopub.status.idle":"2025-03-20T01:14:21.692029Z","shell.execute_reply.started":"2025-03-20T01:14:05.722500Z","shell.execute_reply":"2025-03-20T01:14:21.690373Z"}},"outputs":[{"name":"stdout","text":"Installation du mod√®le fran√ßais SpaCy...\nTraitement de 1 fichiers PDF...\nAnalyse de: 208-modele-cv-informatique.pdf\n\n========== R√âSULTATS DE L'ANALYSE ==========\n\n                          fichier  \\\n0  208-modele-cv-informatique.pdf   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       formations  \\\n0  -curriculum.com FORMATION INFORMATICIEN, Web   EDF 20XX   20XX Ville, Pays   D√©veloppement front ou back en JavaScript., Universit√© ou √©cole   Ville,, Universit√© ou √©cole   Ville, Pays 20XX   20XX, BACCAULAUR√âAT, G√âN√âRAL Universit√© ou √©cole   Ville, Pays 20XX   20XX, Ces documents, ou toute partie de ceux -ci ne peuvent √™tre copi√©s, reproduits, distribu√©s, utilis√©s ou r√©affic h√©s dans d'autres sites web sans le consentement pr√©alable et √©crit d AZURIUS S.L. N'oubliez pas de supprimer cette information copyright avant de modifier et d'imprimer votre CV.   \n\n     comp√©tences_techniques  \\\n0  python, javascript, html   \n\n                                                                                                                                    autres_comp√©tences  \\\n0  HTML, Cr√©ez, Espagnol, marketing, Motivation, France, curriculum.com, outil, applications, LIRE, r√©alisation, Europe, Sport, communication, G√âN√âRAL   \n\n                                                            langues  \n0  fran√ßais (mentionn√©), espagnol (mentionn√©), allemand (mentionn√©)  \n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!pip install PyPDF2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T23:51:11.604459Z","iopub.execute_input":"2025-03-15T23:51:11.604869Z","iopub.status.idle":"2025-03-15T23:51:18.055068Z","shell.execute_reply.started":"2025-03-15T23:51:11.604840Z","shell.execute_reply":"2025-03-15T23:51:18.053661Z"}},"outputs":[{"name":"stdout","text":"Collecting PyPDF2\n  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\nDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: PyPDF2\nSuccessfully installed PyPDF2-3.0.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import spacy\nfrom PyPDF2 import PdfReader\nimport re\n\n# Charger le mod√®le spaCy (version grande pour plus de pr√©cision)\nnlp = spacy.load(\"fr_core_news_lg\")\n\n# Liste de comp√©tences techniques (√† adapter selon vos besoins)\nCOMPETENCES_TECHNIQUES = [\n    \"Python\", \"Java\", \"Machine Learning\", \"SQL\", \"JavaScript\", \"React\", \"Angular\",\n    \"TensorFlow\", \"PyTorch\", \"Git\", \"Docker\", \"AWS\", \"Azure\", \"Linux\", \"HTML\", \"CSS\"\n]\n\n# Fonction pour extraire le texte d'un PDF\ndef extract_text_from_pdf(pdf_path):\n    try:\n        reader = PdfReader(pdf_path)\n        text = \"\"\n        for page in reader.pages:\n            text += page.extract_text()\n        return text\n    except Exception as e:\n        print(f\"Erreur lors de la lecture du PDF : {e}\")\n        return None\n\n# Fonction pour nettoyer le texte\ndef clean_text(text):\n    if text:\n        # Supprimer les sauts de ligne et les espaces multiples\n        text = re.sub(r'\\s+', ' ', text).strip()\n        return text\n    return None\n\n# Fonction pour extraire les formations\ndef extract_formations(text):\n    formations = []\n    # Exemple de motifs pour d√©tecter les formations\n    patterns = [\n        r\"(Licence|Master|Baccalaur√©at|Doctorat|Dipl√¥me|√âcole|Universit√©)[\\s\\w-]+\",\n        r\"\\b(?:Licence|Master|Bac|Doctorat|Dipl√¥me)\\b[\\s\\w-]+\"\n    ]\n    for pattern in patterns:\n        matches = re.findall(pattern, text, re.IGNORECASE)\n        formations.extend(matches)\n    return list(set(formations))  # Supprimer les doublons\n\n# Fonction pour extraire les comp√©tences\ndef extract_competences(text):\n    competences = []\n    # Rechercher les comp√©tences techniques dans le texte\n    for competence in COMPETENCES_TECHNIQUES:\n        if competence.lower() in text.lower():\n            competences.append(competence)\n    return competences\n\n# Fonction pour extraire les langues\ndef extract_langues(text):\n    langues = []\n    # Exemple de motifs pour d√©tecter les langues\n    patterns = [\n        r\"\\b(?:Anglais|Fran√ßais|Espagnol|Allemand|Italien)\\b[\\s\\w-]*(?:courant|interm√©diaire|d√©butant)?\",\n        r\"\\b(?:English|French|Spanish|German|Italian)\\b[\\s\\w-]*(?:fluent|intermediate|basic)?\"\n    ]\n    for pattern in patterns:\n        matches = re.findall(pattern, text, re.IGNORECASE)\n        langues.extend(matches)\n    return list(set(langues))  # Supprimer les doublons\n\n# Fonction principale pour extraire les informations\ndef extract_cv_info(pdf_path):\n    # Extraire le texte du PDF\n    text = extract_text_from_pdf(pdf_path)\n    if not text:\n        return None\n    \n    # Nettoyer le texte\n    text = clean_text(text)\n    \n    # Extraire les informations\n    formations = extract_formations(text)\n    competences = extract_competences(text)\n    langues = extract_langues(text)\n    \n    return {\n        \"formations\": formations,\n        \"competences\": competences,\n        \"langues\": langues\n    }\n\n# Exemple d'utilisation\npdf_path = \"/kaggle/input/cvvvvvvvvvvvvvvvvv/208-modele-cv-informatique.pdf\"\ncv_info = extract_cv_info(pdf_path)\n\nif cv_info:\n    print(\"Formations :\", cv_info[\"formations\"])\n    print(\"Comp√©tences :\", cv_info[\"competences\"])\n    print(\"Langues :\", cv_info[\"langues\"])\nelse:\n    print(\"Erreur lors de l'extraction des informations.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T01:13:06.673099Z","iopub.execute_input":"2025-03-20T01:13:06.673500Z","iopub.status.idle":"2025-03-20T01:13:09.777234Z","shell.execute_reply.started":"2025-03-20T01:13:06.673470Z","shell.execute_reply":"2025-03-20T01:13:09.776429Z"}},"outputs":[{"name":"stdout","text":"Formations : ['Universit√©']\nComp√©tences : ['Python', 'Java', 'JavaScript', 'HTML']\nLangues : ['Fran√ßais Espagnol Allemand LANGUES CENTRES D']\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import fitz  # PyMuPDF pour lire les PDF\nimport spacy\nimport re\n\n# T√©l√©charger le mod√®le fran√ßais de spaCy si ce n'est pas fait\ntry:\n    nlp = spacy.load(\"fr_core_news_lg\")\nexcept OSError:\n    import subprocess\n    subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"fr_core_news_lg\"])\n    nlp = spacy.load(\"fr_core_news_lg\")\n\n\n# Fonction pour extraire le texte d'un PDF\ndef extract_text_from_pdf(pdf_path):\n    try:\n        doc = fitz.open(pdf_path)\n        text = \"\\n\".join([page.get_text(\"text\") for page in doc])\n        return text.strip()\n    except Exception as e:\n        print(f\"Erreur lors de la lecture du PDF : {e}\")\n        return None\n\n\n# Fonction pour analyser le texte et extraire les sections cl√©s\ndef extract_cv_info(text):\n    sections = {\n        \"Nom\": \"\",\n        \"Email\": \"\",\n        \"T√©l√©phone\": \"\",\n        \"Exp√©riences\": \"\",\n        \"Formations\": \"\",\n        \"Comp√©tences\": \"\",\n        \"Langues\": \"\"\n    }\n    \n    # Appliquer spaCy\n    doc = nlp(text)\n\n    # Extraction du nom (en supposant qu'il est en d√©but de document)\n    if doc.ents:\n        sections[\"Nom\"] = doc.ents[0].text  # Premier entit√© (souvent le nom)\n\n    # Extraction des emails\n    email_match = re.search(r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\", text)\n    if email_match:\n        sections[\"Email\"] = email_match.group(0)\n\n    # Extraction du t√©l√©phone\n    phone_match = re.search(r\"\\+?\\d[\\d\\s.-]{8,}\", text)\n    if phone_match:\n        sections[\"T√©l√©phone\"] = phone_match.group(0)\n\n    # Extraction des exp√©riences professionnelles\n    exp_match = re.search(r\"(EXP√âRIENCES|EXP√âRIENCE|EXPERIENCE|TRAVAIL)\\s*:\\s*(.*?)(?:FORMATION|COMP√âTENCES|LANGUES)\", text, re.DOTALL | re.IGNORECASE)\n    if exp_match:\n        sections[\"Exp√©riences\"] = exp_match.group(2).strip()\n\n    # Extraction des formations\n    formation_match = re.search(r\"(FORMATION|√âDUCATION|DIPL√îMES)\\s*:\\s*(.*?)(?:EXP√âRIENCES|COMP√âTENCES|LANGUES)\", text, re.DOTALL | re.IGNORECASE)\n    if formation_match:\n        sections[\"Formations\"] = formation_match.group(2).strip()\n\n    # Extraction des comp√©tences\n    competences_match = re.search(r\"(COMP√âTENCES|SKILLS)\\s*:\\s*(.*?)(?:EXP√âRIENCES|FORMATION|LANGUES)\", text, re.DOTALL | re.IGNORECASE)\n    if competences_match:\n        sections[\"Comp√©tences\"] = competences_match.group(2).strip()\n\n    # Extraction des langues\n    langues_match = re.search(r\"(LANGUES|LANGUAGE)\\s*:\\s*(.*?)(?:EXP√âRIENCES|FORMATION|COMP√âTENCES)\", text, re.DOTALL | re.IGNORECASE)\n    if langues_match:\n        sections[\"Langues\"] = langues_match.group(2).strip()\n\n    return sections\n\n\n# Fonction principale\ndef process_cv(pdf_path):\n    # Extraire le texte\n    text = extract_text_from_pdf(pdf_path)\n    if not text:\n        return None\n\n    # Extraire les infos du CV\n    cv_info = extract_cv_info(text)\n    \n    return cv_info\n\n\n# üìÑ Exemple d'utilisation\npdf_path = \"/kaggle/input/cvvvvvvvvvv/cvwail.pdf\"  # Remplace avec ton vrai fichier PDF\ncv_info = process_cv(pdf_path)\n\nif cv_info:\n    for key, value in cv_info.items():\n        print(f\"{key}: {value}\")\nelse:\n    print(\"Erreur lors de l'extraction des informations.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T02:04:17.316296Z","iopub.execute_input":"2025-03-20T02:04:17.316807Z","iopub.status.idle":"2025-03-20T02:04:20.927591Z","shell.execute_reply.started":"2025-03-20T02:04:17.316774Z","shell.execute_reply":"2025-03-20T02:04:20.926655Z"}},"outputs":[{"name":"stdout","text":"Nom: Exp√©rience professionnelle\nCONTACT\nEmail: benharatswail@gmail.com\nT√©l√©phone: 0661990707\n\nExp√©riences: \nFormations: \nComp√©tences: \nLangues: \n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"!pip install langchain langchain-community openai\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T01:31:43.297147Z","iopub.execute_input":"2025-03-20T01:31:43.297633Z","iopub.status.idle":"2025-03-20T01:31:55.110218Z","shell.execute_reply.started":"2025-03-20T01:31:43.297595Z","shell.execute_reply":"2025-03-20T01:31:55.108971Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.12)\nCollecting langchain-community\n  Downloading langchain_community-0.3.20-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.57.4)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.12)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\nRequirement already satisfied: langchain-core<0.4.0,>=0.3.25 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.25)\nRequirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.3)\nRequirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\nRequirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.11.0a2)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\nCollecting langchain-core<0.4.0,>=0.3.25 (from langchain)\n  Downloading langchain_core-0.3.46-py3-none-any.whl.metadata (5.9 kB)\nCollecting langchain\n  Downloading langchain-0.3.21-py3-none-any.whl.metadata (7.8 kB)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\nCollecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\nCollecting langchain-text-splitters<1.0.0,>=0.3.7 (from langchain)\n  Downloading langchain_text_splitters-0.3.7-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\nRequirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\nRequirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (24.2)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.29.0)\nCollecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.3.0)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.25->langchain) (3.0.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.22.4->langchain) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.22.4->langchain) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1.22.4->langchain) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2,>=1.22.4->langchain) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2,>=1.22.4->langchain) (2024.2.0)\nDownloading langchain_community-0.3.20-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain-0.3.21-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nDownloading langchain_core-0.3.46-py3-none-any.whl (417 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m417.1/417.1 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.3.7-py3-none-any.whl (32 kB)\nDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\nDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\nInstalling collected packages: python-dotenv, httpx-sse, pydantic-settings, langchain-core, langchain-text-splitters, langchain, langchain-community\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.25\n    Uninstalling langchain-core-0.3.25:\n      Successfully uninstalled langchain-core-0.3.25\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.3.3\n    Uninstalling langchain-text-splitters-0.3.3:\n      Successfully uninstalled langchain-text-splitters-0.3.3\n  Attempting uninstall: langchain\n    Found existing installation: langchain 0.3.12\n    Uninstalling langchain-0.3.12:\n      Successfully uninstalled langchain-0.3.12\nSuccessfully installed httpx-sse-0.4.0 langchain-0.3.21 langchain-community-0.3.20 langchain-core-0.3.46 langchain-text-splitters-0.3.7 pydantic-settings-2.8.1 python-dotenv-1.0.1\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"pip install PyPDF2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T13:28:31.010516Z","iopub.execute_input":"2025-03-20T13:28:31.010888Z","iopub.status.idle":"2025-03-20T13:28:37.209343Z","shell.execute_reply.started":"2025-03-20T13:28:31.010855Z","shell.execute_reply":"2025-03-20T13:28:37.207995Z"}},"outputs":[{"name":"stdout","text":"Collecting PyPDF2\n  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\nDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: PyPDF2\nSuccessfully installed PyPDF2-3.0.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pdfplumber\nfrom transformers import pipeline\n\n# üîπ Extraction du texte du PDF\ndef extract_text_from_pdf(pdf_path):\n    with pdfplumber.open(pdf_path) as pdf:\n        return \"\\n\".join([page.extract_text() for page in pdf.pages if page.extract_text()])\n\n# üîπ Chargement du mod√®le NER\nner_pipeline = pipeline(\"ner\", model=\"Jean-Baptiste/camembert-ner\", tokenizer=\"Jean-Baptiste/camembert-ner\", aggregation_strategy=\"simple\")\n\n# üîπ Listes de contr√¥le pour classification\nFORMATION_KEYWORDS = [\"Universit√©\", \"√âcole\", \"Master\", \"Licence\", \"Bac\", \"Certification\", \"Doctorat\"]\nEXPERIENCE_EXCLUDE = [\"University\", \"√âcole\", \"Institut\", \"College\"]\nCOMPETENCES_LIST = [\"Python\", \"Java\", \"Django\", \"SQL\", \"FastAPI\", \"React\", \"Machine Learning\", \"Deep Learning\", \"Hadoop\"]\nLANGUES_LIST = [\"Fran√ßais\", \"Anglais\", \"Arabe\", \"Espagnol\", \"Allemand\"]\nLIEUX_LIST = [\"Maroc\", \"Rabat\", \"France\", \"Belgique\", \"Canada\"]  # Exclure des formations\n\n# üîπ Fonction am√©lior√©e de classification\ndef categorize_entities(entities):\n    categories = {\n        \"Exp√©riences\": [],\n        \"Formations\": [],\n        \"Comp√©tences\": [],\n        \"Langues\": [],\n    }\n\n    for entity in entities:\n        text = entity[\"word\"]\n        label = entity[\"entity_group\"]\n\n        # üîπ Correction des exp√©riences\n        if label in [\"PER\", \"ORG\"]:\n            if any(word in text for word in EXPERIENCE_EXCLUDE):\n                categories[\"Formations\"].append(text)  \n            else:\n                categories[\"Exp√©riences\"].append(text)\n\n        # üîπ Correction des formations\n        elif label in [\"MISC\"]:\n            if text in LIEUX_LIST:  \n                continue  # Ignore les lieux\n            if any(word in text for word in FORMATION_KEYWORDS):\n                categories[\"Formations\"].append(text)\n            else:\n                categories[\"Comp√©tences\"].append(text)\n\n        # üîπ Correction des comp√©tences\n        elif label in [\"LOC\"]:  \n            if text in COMPETENCES_LIST:\n                categories[\"Comp√©tences\"].append(text)\n            else:\n                categories[\"Formations\"].append(text)\n\n        # üîπ Ajout des langues\n        if text in LANGUES_LIST:\n            categories[\"Langues\"].append(text)\n\n    return {key: list(set(value)) for key, value in categories.items()}  # Suppression des doublons\n\n# üîπ Fonction principale\ndef process_cv(pdf_path):\n    text = extract_text_from_pdf(pdf_path)\n    entities = ner_pipeline(text)\n    return categorize_entities(entities)\n\n# üî• Test avec un CV\ncv_path = \"/kaggle/input/cvvvvvvvvvv/cvwail.pdf\"\nresult = process_cv(cv_path)\nprint(result)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T12:08:02.896316Z","iopub.execute_input":"2025-03-20T12:08:02.896660Z","iopub.status.idle":"2025-03-20T12:08:04.461864Z","shell.execute_reply.started":"2025-03-20T12:08:02.896632Z","shell.execute_reply":"2025-03-20T12:08:04.460936Z"}},"outputs":[{"name":"stderr","text":"Device set to use cpu\n","output_type":"stream"},{"name":"stdout","text":"{'Exp√©riences': ['EMSI', 'WAIL BENHARRATS', 'Wail Benharrats'], 'Formations': ['Universit√© C√¥te d‚ÄôAzure', 'University of Michigan', 'Maroc', \"√âcole Marocaine des Sciences de l'Ing√©nieur\", 'Lyc√©e scientifique Tour Hassan', 'Rabat'], 'Comp√©tences': ['Django', 'Pig,Hive', 'UML', 'C# Anglais', 'web Entreprise DIRHAM EXPRESS', 'Data', 'Oracle Outils ETL', 'de Donn√©es', 'SQL', 'FastAPI', 'PL/SQL', 'Programmation', 'Arabe', 'MySQL Server', 'UML Application Web de Gestion des Cong√©s Python for everybody', 'Projets academiques', 'Spring Boot Application Web de Gestion des employ√©s et stocks', 'JEE Fran√ßais', '.NET', 'Microsoft Azure Sport', 'Entreprise ECONOCOM', 'Talend Open Studio', 'Spring Boot', 'Python', 'Base', 'Mobile', 'Oracle Database Administration I', 'Hadoop MapReduce', 'C,C++', 'Unix System Basics', 'T-SQL', 'Fast API', 'React Basics', 'Java', 'Langages', 'Merise', 'Android Studio b√©n√©volat'], 'Langues': ['Arabe']}\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Installer les biblioth√®ques n√©cessaires\n\n\n# Importer les biblioth√®ques\nimport PyPDF2\nimport json\nimport os\nimport requests\nimport pandas as pd\nfrom IPython.display import display, HTML\n\n# Configurer l'API key directement\nopenai_api_key = \"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\"  # Remplacez par votre cl√© API OpenAI r√©elle\n\n# Fonction pour extraire le texte du PDF\ndef extract_text_from_pdf(pdf_path):\n    with open(pdf_path, \"rb\") as file:\n        reader = PyPDF2.PdfReader(file)\n        text = \"\"\n        for page in reader.pages:\n            text += page.extract_text()\n    return text\n\n# Fonction pour analyser le CV avec une API\ndef analyze_cv(cv_text):\n    headers = {\n        \"Authorization\": f\"Bearer {openai_api_key}\",\n        \"Content-Type\": \"application/json\"\n    }\n    \n    data = {\n        \"model\": \"gpt-3.5-turbo\",  # Mod√®le modifi√© √† gpt-3.5-turbo\n        \"messages\": [\n            {\n                \"role\": \"system\",\n                \"content\": \"Extrais les informations suivantes du CV: formations, exp√©riences professionnelles, comp√©tences, langues. R√©ponds uniquement en format JSON.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": cv_text\n            }\n        ]\n    }\n    \n    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=data)\n    return response.json()\n\n# Exemple d'utilisation\ncv_folder = \"/kaggle/input/cvvvvvvvvvv\"  # Chemin vers votre dossier de CVs\nresults = []\n\n# Analyser les CV\nfor filename in os.listdir(cv_folder)[:3]:  # Limite √† 3 fichiers pour la d√©mo\n    if filename.endswith(\".pdf\"):\n        pdf_path = os.path.join(cv_folder, filename)\n        print(f\"Traitement du fichier: {filename}\")\n        \n        cv_text = extract_text_from_pdf(pdf_path)\n        cv_data = analyze_cv(cv_text)\n        \n        # Extraire le contenu r√©el du JSON de la r√©ponse de l'API\n        try:\n            # La structure exacte d√©pend de l'API que vous utilisez\n            content = json.loads(cv_data['choices'][0]['message']['content'])\n            \n            # Afficher les informations structur√©es\n            print(f\"\\n--- R√©sultats pour {filename} ---\")\n            print(f\"Formations: {content.get('formations', 'Non disponible')}\")\n            print(f\"Exp√©riences: {content.get('exp√©riences professionnelles', 'Non disponible')}\")\n            print(f\"Comp√©tences: {content.get('comp√©tences', 'Non disponible')}\")\n            print(f\"Langues: {content.get('langues', 'Non disponible')}\")\n            print(\"\\n\" + \"-\"*50 + \"\\n\")\n            \n            results.append({\n                \"filename\": filename,\n                \"formations\": content.get('formations', []),\n                \"experiences\": content.get('exp√©riences professionnelles', []),\n                \"competences\": content.get('comp√©tences', []),\n                \"langues\": content.get('langues', [])\n            })\n        except Exception as e:\n            print(f\"Erreur lors du traitement de {filename}: {e}\")\n            print(f\"R√©ponse brute: {cv_data}\")\n\n# Cr√©er un DataFrame pour une visualisation plus structur√©e\nif results:\n    df = pd.DataFrame(results)\n    display(df)\n    \n    # Vous pouvez √©galement cr√©er un tableau HTML plus √©labor√©\n    html_output = \"<h2>Analyse d√©taill√©e des CV</h2>\"\n    for result in results:\n        html_output += f\"<h3>CV: {result['filename']}</h3>\"\n        html_output += \"<table border='1'>\"\n        html_output += \"<tr><th>Cat√©gorie</th><th>D√©tails</th></tr>\"\n        html_output += f\"<tr><td>Formations</td><td>{result['formations']}</td></tr>\"\n        html_output += f\"<tr><td>Exp√©riences</td><td>{result['experiences']}</td></tr>\"\n        html_output += f\"<tr><td>Comp√©tences</td><td>{result['competences']}</td></tr>\"\n        html_output += f\"<tr><td>Langues</td><td>{result['langues']}</td></tr>\"\n        html_output += \"</table><br>\"\n    \n    display(HTML(html_output))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T15:01:24.585216Z","iopub.execute_input":"2025-03-20T15:01:24.585631Z","iopub.status.idle":"2025-03-20T15:01:26.056146Z","shell.execute_reply.started":"2025-03-20T15:01:24.585601Z","shell.execute_reply":"2025-03-20T15:01:26.055247Z"}},"outputs":[{"name":"stdout","text":"Traitement du fichier: cvwail.pdf\nErreur lors du traitement de cvwail.pdf: 'choices'\nR√©ponse brute: {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"pip install PyPDF2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T15:01:08.891277Z","iopub.execute_input":"2025-03-20T15:01:08.891625Z","iopub.status.idle":"2025-03-20T15:01:15.054669Z","shell.execute_reply.started":"2025-03-20T15:01:08.891601Z","shell.execute_reply":"2025-03-20T15:01:15.053511Z"}},"outputs":[{"name":"stdout","text":"Collecting PyPDF2\n  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\nDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: PyPDF2\nSuccessfully installed PyPDF2-3.0.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Installer les biblioth√®ques n√©cessaires\n!pip install PyPDF2\n!pip install requests\n!pip install pandas\n\n# Importer les biblioth√®ques\nimport PyPDF2\nimport requests\nimport json\nimport pandas as pd\nimport os\nfrom IPython.display import display, HTML\n\n# Configurer l'API key directement\nquen_api_key = \"votre-cl√©-api-quen-ici\"  # Remplacez par votre cl√© API Quen AI\n\n# Fonction pour extraire le texte du PDF\ndef extract_text_from_pdf(pdf_path):\n    with open(pdf_path, \"rb\") as file:\n        reader = PyPDF2.PdfReader(file)\n        text = \"\"\n        for page in reader.pages:\n            text += page.extract_text()\n    return text\n\n# Fonction pour analyser le CV avec l'API Quen AI\ndef analyze_cv_with_quen(cv_text):\n    headers = {\n        \"Content-Type\": \"application/json\",\n        \"Authorization\": f\"Bearer {quen_api_key}\"  # Authentification via Bearer Token\n    }\n    \n    # Structure de la requ√™te pour Quen AI (√† adapter selon la documentation)\n    data = {\n        \"text\": cv_text,  # Texte du CV\n        \"tasks\": [\"extract_formations\", \"extract_experiences\", \"extract_competences\", \"extract_langues\"],  # T√¢ches √† effectuer\n        \"format\": \"json\"  # Format de la r√©ponse\n    }\n    \n    # Endpoint de l'API Quen AI (√† adapter selon la documentation)\n    response = requests.post(\"https://api.quen.ai/v1/analyze\", headers=headers, json=data)\n    return response.json()\n\n# Exemple d'utilisation\ncv_folder = \"/kaggle/input/cv-dataset/\"  # Chemin vers votre dossier de CVs\nresults = []\n\n# Analyser les CV\nfor filename in os.listdir(cv_folder):  # Traitez tous les fichiers\n    if filename.endswith(\".pdf\"):\n        pdf_path = os.path.join(cv_folder, filename)\n        print(f\"Traitement du fichier: {filename}\")\n        \n        cv_text = extract_text_from_pdf(pdf_path)\n        cv_data = analyze_cv_with_quen(cv_text)\n        \n        # Extraire le contenu r√©el du JSON de la r√©ponse de l'API\n        try:\n            # La structure exacte d√©pend de l'API Quen AI\n            content = cv_data.get('results', {})\n            \n            # Afficher les informations structur√©es\n            print(f\"\\n--- R√©sultats pour {filename} ---\")\n            print(f\"Formations: {content.get('formations', 'Non disponible')}\")\n            print(f\"Exp√©riences: {content.get('experiences', 'Non disponible')}\")\n            print(f\"Comp√©tences: {content.get('competences', 'Non disponible')}\")\n            print(f\"Langues: {content.get('langues', 'Non disponible')}\")\n            print(\"\\n\" + \"-\"*50 + \"\\n\")\n            \n            results.append({\n                \"filename\": filename,\n                \"formations\": content.get('formations', []),\n                \"experiences\": content.get('experiences', []),\n                \"competences\": content.get('competences', []),\n                \"langues\": content.get('langues', [])\n            })\n        except Exception as e:\n            print(f\"Erreur lors du traitement de {filename}: {e}\")\n            print(f\"R√©ponse brute: {cv_data}\")\n\n# Cr√©er un DataFrame pour une visualisation plus structur√©e\nif results:\n    # Cr√©ation d'un DataFrame pour une vue d'ensemble\n    df = pd.DataFrame(results)\n    display(df)\n    \n    # Cr√©ation d'une visualisation HTML plus d√©taill√©e\n    html_output = \"<h2>Analyse d√©taill√©e des CV</h2>\"\n    for result in results:\n        html_output += f\"<h3>CV: {result['filename']}</h3>\"\n        html_output += \"<table border='1' width='100%'>\"\n        html_output += \"<tr><th>Cat√©gorie</th><th>D√©tails</th></tr>\"\n        \n        # Formations\n        html_output += \"<tr><td style='width:20%; font-weight:bold; vertical-align:top;'>Formations</td><td>\"\n        if result['formations']:\n            html_output += \"<ul>\"\n            for item in result['formations']:\n                html_output += f\"<li>{item}</li>\"\n            html_output += \"</ul>\"\n        else:\n            html_output += \"Non disponible\"\n        html_output += \"</td></tr>\"\n        \n        # Exp√©riences\n        html_output += \"<tr><td style='font-weight:bold; vertical-align:top;'>Exp√©riences</td><td>\"\n        if result['experiences']:\n            html_output += \"<ul>\"\n            for item in result['experiences']:\n                html_output += f\"<li>{item}</li>\"\n            html_output += \"</ul>\"\n        else:\n            html_output += \"Non disponible\"\n        html_output += \"</td></tr>\"\n        \n        # Comp√©tences\n        html_output += \"<tr><td style='font-weight:bold; vertical-align:top;'>Comp√©tences</td><td>\"\n        if result['competences']:\n            html_output += \"<ul>\"\n            for item in result['competences']:\n                html_output += f\"<li>{item}</li>\"\n            html_output += \"</ul>\"\n        else:\n            html_output += \"Non disponible\"\n        html_output += \"</td></tr>\"\n        \n        # Langues\n        html_output += \"<tr><td style='font-weight:bold; vertical-align:top;'>Langues</td><td>\"\n        if result['langues']:\n            html_output += \"<ul>\"\n            for item in result['langues']:\n                html_output += f\"<li>{item}</li>\"\n            html_output += \"</ul>\"\n        else:\n            html_output += \"Non disponible\"\n        html_output += \"</td></tr>\"\n        \n        html_output += \"</table><br><hr><br>\"\n    \n    # Affichage du tableau HTML\n    display(HTML(html_output))\n    \n    # G√©n√©rer quelques statistiques\n    print(\"Statistiques sur les CV analys√©s:\")\n    print(f\"Nombre total de CV: {len(results)}\")\n    \n    # Calculer le nombre moyen d'exp√©riences par CV\n    avg_exp = sum(len(r['experiences']) for r in results) / len(results) if results else 0\n    print(f\"Nombre moyen d'exp√©riences professionnelles par CV: {avg_exp:.2f}\")\n    \n    # Calculer le nombre moyen de formations par CV\n    avg_form = sum(len(r['formations']) for r in results) / len(results) if results else 0\n    print(f\"Nombre moyen de formations par CV: {avg_form:.2f}\")\n    \n    # Calculer le nombre moyen de comp√©tences par CV\n    avg_comp = sum(len(r['competences']) for r in results) / len(results) if results else 0\n    print(f\"Nombre moyen de comp√©tences par CV: {avg_comp:.2f}\")\nelse:\n    print(\"Aucun CV n'a pu √™tre analys√©. V√©rifiez le chemin du dossier et le format des fichiers.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T15:08:28.114788Z","iopub.execute_input":"2025-03-20T15:08:28.115427Z","iopub.status.idle":"2025-03-20T15:09:37.093744Z","shell.execute_reply.started":"2025-03-20T15:08:28.115388Z","shell.execute_reply":"2025-03-20T15:09:37.092576Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\nRequirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.11)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.5.0)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.15.1)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.67.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.11.0a2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.5.0)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.29.0)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spacy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spacy) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->spacy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.19.0->spacy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.19.0->spacy) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\nCollecting fr-core-news-lg==3.7.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_lg-3.7.0/fr_core_news_lg-3.7.0-py3-none-any.whl (571.8 MB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m571.8/571.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from fr-core-news-lg==3.7.0) (3.7.5)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (1.0.11)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2.0.10)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2.5.0)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (0.15.1)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (4.67.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2.11.0a2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (3.1.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (75.1.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (24.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (3.5.0)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2.29.0)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2025.1.31)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (13.9.4)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (7.0.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (3.0.2)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2.19.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.19.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (0.1.2)\nInstalling collected packages: fr-core-news-lg\nSuccessfully installed fr-core-news-lg-3.7.0\n\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('fr_core_news_lg')\n\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\nRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.4->pandas) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.22.4->pandas) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.22.4->pandas) (2024.2.0)\nTraitement du fichier: cvwail.pdf\n\n--- R√©sultats pour cvwail.pdf ---\nFormations: [\"Exp√©rience professionnelleCONTACT\\nConception et d√©veloppement complet d'une application web de\\ngestion des cong√©s utilisant FastAPI, un framework Python pour\\nles API web.\\nD√©veloppement des fonctionnalit√©s de gestion des demandes\\nde cong√©s, de suivi des cong√©s disponibles, et de g√©n√©ration de\\nrapports pour les employ√©s et les managers.\\nConception et d√©veloppement complet d'une application web de\\ngestion des employ√©s et stocks en utilisant Django et en int√©grant\\ndans le projet la reconnaissance faciale et les d√©tection des objets .\\nConnaissances techniques Projets academiquesformation Academique\\nCertifications\\nOracle Database Administration I\\n(2024)\\ning√©nierie logicielle (2023)\\n Mod√©lisation des syst√®mes \\n logiciels a l‚Äôaide de l‚ÄôUML\\nPython for everybody - University of\\nMichigan (2023)\\nReact Basics (2023)\\nUnix System Basics (2023)\\nLangues0661990707\\nbenharatswail@gmail.com\\nRabat, MarocWAIL BENHARRATS\\nFutur ing√©nieur en informatique option\\nMIAGE √† l‚ÄôEMSI √† la recherche d‚Äôun stage\\nPFE √† partir du mois de mars \\nAnglais : niveau c1\\nFran√ßais : niveau c1\\nArabe : langue maternelleWail Benharrats\\n07/2023-08/2023 - Stage de fin d‚Äôann√©e\\nEntreprise ECONOCOM\\nApplication Web de Gestion des Cong√©s\\n07/2024-08/2024 - Stage de de fin d‚Äôann√©e\\nEntreprise DIRHAM EXPRESS\\nApplication Web de Gestion des employ√©s et stocksOctobre 2024  \\n Master MIAGE IA2 Universit√© C√¥te d‚ÄôAzure\\n2020-2025\\n Dipl√¥me d'ing√©nieur en informatique et r√©seaux \\n √âcole Marocaine des Sciences de l'Ing√©nieur\\n2019-2020\\nBac Sciences Physiques\\nLyc√©e scientifique Tour Hassan\\nLangages de Programmation : C,C++, Java, Python, C#\\nFrameworks : Django,Fast API,.NET,Spring Boot,JEE\\nBases de Donn√©es : SQL, T-SQL, PL/SQL, MySQL Server,\\nOracle\\nOutils ETL : Talend Open Studio\\nBig Data : Hadoop MapReduce,Pig,Hive, Microsoft Azure\\nConception et Mod√©lisation : Merise, UML\\nD√©veloppement Mobile : Android StudioProjet Fin d‚Äôann√©e de la 4eme ann√©e\\nR√©alisation d‚Äôune application web\\nd‚Äôarchivage en utilisant Spring Boot\\nProjet Fin d‚Äôann√©e de la 3eme ann√©e\\nR√©alisation d‚Äôune application web de\\ngestion d'√©cole en utilisant Django\\nCentre d‚Äôint√©r√™ts\\nSport\\nSuivi des tendances technologiques\\nb√©n√©volat\"]\nExp√©riences: []\nComp√©tences: []\nLangues: []\n\n--------------------------------------------------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"     filename                                         formations experiences  \\\n0  cvwail.pdf  [Exp√©rience professionnelleCONTACT\\nConception...          []   \n\n  competences langues  \n0          []      []  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>formations</th>\n      <th>experiences</th>\n      <th>competences</th>\n      <th>langues</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cvwail.pdf</td>\n      <td>[Exp√©rience professionnelleCONTACT\\nConception...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<h2>Analyse d√©taill√©e des CV</h2><h3>CV: cvwail.pdf</h3><table border='1' width='100%'><tr><th>Cat√©gorie</th><th>D√©tails</th></tr><tr><td style='width:20%; font-weight:bold; vertical-align:top;'>Formations</td><td><ul><li>Exp√©rience professionnelleCONTACT\nConception et d√©veloppement complet d'une application web de\ngestion des cong√©s utilisant FastAPI, un framework Python pour\nles API web.\nD√©veloppement des fonctionnalit√©s de gestion des demandes\nde cong√©s, de suivi des cong√©s disponibles, et de g√©n√©ration de\nrapports pour les employ√©s et les managers.\nConception et d√©veloppement complet d'une application web de\ngestion des employ√©s et stocks en utilisant Django et en int√©grant\ndans le projet la reconnaissance faciale et les d√©tection des objets .\nConnaissances techniques Projets academiquesformation Academique\nCertifications\nOracle Database Administration I\n(2024)\ning√©nierie logicielle (2023)\n Mod√©lisation des syst√®mes \n logiciels a l‚Äôaide de l‚ÄôUML\nPython for everybody - University of\nMichigan (2023)\nReact Basics (2023)\nUnix System Basics (2023)\nLangues0661990707\nbenharatswail@gmail.com\nRabat, MarocWAIL BENHARRATS\nFutur ing√©nieur en informatique option\nMIAGE √† l‚ÄôEMSI √† la recherche d‚Äôun stage\nPFE √† partir du mois de mars \nAnglais : niveau c1\nFran√ßais : niveau c1\nArabe : langue maternelleWail Benharrats\n07/2023-08/2023 - Stage de fin d‚Äôann√©e\nEntreprise ECONOCOM\nApplication Web de Gestion des Cong√©s\n07/2024-08/2024 - Stage de de fin d‚Äôann√©e\nEntreprise DIRHAM EXPRESS\nApplication Web de Gestion des employ√©s et stocksOctobre 2024  \n Master MIAGE IA2 Universit√© C√¥te d‚ÄôAzure\n2020-2025\n Dipl√¥me d'ing√©nieur en informatique et r√©seaux \n √âcole Marocaine des Sciences de l'Ing√©nieur\n2019-2020\nBac Sciences Physiques\nLyc√©e scientifique Tour Hassan\nLangages de Programmation : C,C++, Java, Python, C#\nFrameworks : Django,Fast API,.NET,Spring Boot,JEE\nBases de Donn√©es : SQL, T-SQL, PL/SQL, MySQL Server,\nOracle\nOutils ETL : Talend Open Studio\nBig Data : Hadoop MapReduce,Pig,Hive, Microsoft Azure\nConception et Mod√©lisation : Merise, UML\nD√©veloppement Mobile : Android StudioProjet Fin d‚Äôann√©e de la 4eme ann√©e\nR√©alisation d‚Äôune application web\nd‚Äôarchivage en utilisant Spring Boot\nProjet Fin d‚Äôann√©e de la 3eme ann√©e\nR√©alisation d‚Äôune application web de\ngestion d'√©cole en utilisant Django\nCentre d‚Äôint√©r√™ts\nSport\nSuivi des tendances technologiques\nb√©n√©volat</li></ul></td></tr><tr><td style='font-weight:bold; vertical-align:top;'>Exp√©riences</td><td>Non disponible</td></tr><tr><td style='font-weight:bold; vertical-align:top;'>Comp√©tences</td><td>Non disponible</td></tr><tr><td style='font-weight:bold; vertical-align:top;'>Langues</td><td>Non disponible</td></tr></table><br><hr><br>"},"metadata":{}},{"name":"stdout","text":"Statistiques sur les CV analys√©s:\nNombre total de CV: 1\nNombre moyen d'exp√©riences professionnelles par CV: 0.00\nNombre moyen de formations par CV: 1.00\nNombre moyen de comp√©tences par CV: 0.00\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Installer les biblioth√®ques n√©cessaires\n!pip install PyPDF2\n!pip install requests\n!pip install pandas\n!pip install -U google-generativeai  # Mettre √† jour √† la derni√®re version\n\n# Importer les biblioth√®ques\nimport PyPDF2\nimport requests\nimport json\nimport pandas as pd\nimport os\nfrom IPython.display import display, HTML\nimport google.generativeai as genai\n\n# Configurer l'API key pour Gemini\ngemini_api_key = \"AIzaSyD_TbpEKWfOM5bnzfON8UjtTfrffwu29HQ\"  # Remplacez par votre cl√© API Gemini\ngenai.configure(api_key=gemini_api_key)\n\n# Fonction pour extraire le texte du PDF\ndef extract_text_from_pdf(pdf_path):\n    with open(pdf_path, \"rb\") as file:\n        reader = PyPDF2.PdfReader(file)\n        text = \"\"\n        for page in reader.pages:\n            text += page.extract_text()\n    return text\n\n# Fonction pour analyser le CV avec l'API Gemini\ndef analyze_cv_with_gemini(cv_text):\n    try:\n        # Obtenir la liste des mod√®les disponibles\n        models = genai.list_models()\n        # Afficher les mod√®les disponibles pour le d√©bogage\n        print(\"Mod√®les disponibles:\")\n        for model in models:\n            print(f\"- {model.name}\")\n        \n        # S√©lectionner le premier mod√®le de type text\n        gemini_model = None\n        for model in models:\n            if \"gemini\" in model.name.lower() and \"generateContent\" in [m.name for m in model.supported_methods]:\n                gemini_model = model.name\n                print(f\"Utilisation du mod√®le: {gemini_model}\")\n                break\n        \n        if not gemini_model:\n            # Fallback sur un nom courant si aucun mod√®le n'a √©t√© trouv√©\n            gemini_model = \"models/gemini-1.5-pro\"\n            print(f\"Aucun mod√®le trouv√©, tentative avec: {gemini_model}\")\n        \n        # Cr√©er le mod√®le Gemini\n        model = genai.GenerativeModel(gemini_model)\n        \n        # Cr√©er un prompt pour extraire les informations du CV\n        prompt = f\"\"\"\n        Analyse le CV suivant et extrait ces informations exactes au format JSON:\n        1. formations: liste des formations (dipl√¥mes, √©tablissements, dates)\n        2. experiences: liste des exp√©riences professionnelles (postes, entreprises, dates, descriptions)\n        3. competences: liste des comp√©tences techniques et non-techniques\n        4. langues: liste des langues ma√Ætris√©es avec leur niveau\n\n        CV:\n        {cv_text}\n\n        R√©ponds uniquement avec un objet JSON valide contenant ces 4 cat√©gories sans texte suppl√©mentaire.\n        \"\"\"\n        \n        # Appeler l'API Gemini\n        response = model.generate_content(prompt)\n        \n        # Extraire et parser la r√©ponse JSON\n        response_text = response.text\n        # Trouver et extraire le JSON (entre accolades)\n        start_idx = response_text.find('{')\n        end_idx = response_text.rfind('}') + 1\n        \n        if start_idx != -1 and end_idx != -1:\n            json_str = response_text[start_idx:end_idx]\n            return json.loads(json_str)\n        else:\n            # Si on ne trouve pas de JSON, on retourne la r√©ponse brute\n            return {\"error\": \"Pas de JSON trouv√© dans la r√©ponse\", \"raw_response\": response_text}\n    except Exception as e:\n        return {\"error\": str(e), \"raw_response\": str(e)}\n\n# Exemple d'utilisation\ncv_folder = \"/kaggle/input/cvvvvvvvvvv\"  # Chemin vers votre dossier de CVs\nresults = []\n\n# Analyser les CV\nfor filename in os.listdir(cv_folder):  # Traitez tous les fichiers\n    if filename.endswith(\".pdf\"):\n        pdf_path = os.path.join(cv_folder, filename)\n        print(f\"Traitement du fichier: {filename}\")\n        \n        cv_text = extract_text_from_pdf(pdf_path)\n        cv_data = analyze_cv_with_gemini(cv_text)\n        \n        # Extraire le contenu r√©el du JSON de la r√©ponse de l'API\n        try:\n            # V√©rifier si une erreur est survenue\n            if \"error\" in cv_data:\n                print(f\"Erreur lors de l'analyse de {filename}: {cv_data['error']}\")\n                continue\n            \n            # Afficher les informations structur√©es\n            print(f\"\\n--- R√©sultats pour {filename} ---\")\n            print(f\"Formations: {cv_data.get('formations', 'Non disponible')}\")\n            print(f\"Exp√©riences: {cv_data.get('experiences', 'Non disponible')}\")\n            print(f\"Comp√©tences: {cv_data.get('competences', 'Non disponible')}\")\n            print(f\"Langues: {cv_data.get('langues', 'Non disponible')}\")\n            print(\"\\n\" + \"-\"*50 + \"\\n\")\n            \n            results.append({\n                \"filename\": filename,\n                \"formations\": cv_data.get('formations', []),\n                \"experiences\": cv_data.get('experiences', []),\n                \"competences\": cv_data.get('competences', []),\n                \"langues\": cv_data.get('langues', [])\n            })\n        except Exception as e:\n            print(f\"Erreur lors du traitement de {filename}: {e}\")\n            print(f\"R√©ponse brute: {cv_data}\")\n\n# Cr√©er un DataFrame pour une visualisation plus structur√©e\nif results:\n    # Cr√©ation d'un DataFrame pour une vue d'ensemble\n    df = pd.DataFrame(results)\n    display(df)\n    \n    # Cr√©ation d'une visualisation HTML plus d√©taill√©e\n    html_output = \"<h2>Analyse d√©taill√©e des CV</h2>\"\n    for result in results:\n        html_output += f\"<h3>CV: {result['filename']}</h3>\"\n        html_output += \"<table border='1' width='100%'>\"\n        html_output += \"<tr><th>Cat√©gorie</th><th>D√©tails</th></tr>\"\n        \n        # Formations\n        html_output += \"<tr><td style='width:20%; font-weight:bold; vertical-align:top;'>Formations</td><td>\"\n        if result['formations']:\n            html_output += \"<ul>\"\n            for item in result['formations']:\n                html_output += f\"<li>{item}</li>\"\n            html_output += \"</ul>\"\n        else:\n            html_output += \"Non disponible\"\n        html_output += \"</td></tr>\"\n        \n        # Exp√©riences\n        html_output += \"<tr><td style='font-weight:bold; vertical-align:top;'>Exp√©riences</td><td>\"\n        if result['experiences']:\n            html_output += \"<ul>\"\n            for item in result['experiences']:\n                html_output += f\"<li>{item}</li>\"\n            html_output += \"</ul>\"\n        else:\n            html_output += \"Non disponible\"\n        html_output += \"</td></tr>\"\n        \n        # Comp√©tences\n        html_output += \"<tr><td style='font-weight:bold; vertical-align:top;'>Comp√©tences</td><td>\"\n        if result['competences']:\n            html_output += \"<ul>\"\n            for item in result['competences']:\n                html_output += f\"<li>{item}</li>\"\n            html_output += \"</ul>\"\n        else:\n            html_output += \"Non disponible\"\n        html_output += \"</td></tr>\"\n        \n        # Langues\n        html_output += \"<tr><td style='font-weight:bold; vertical-align:top;'>Langues</td><td>\"\n        if result['langues']:\n            html_output += \"<ul>\"\n            for item in result['langues']:\n                html_output += f\"<li>{item}</li>\"\n            html_output += \"</ul>\"\n        else:\n            html_output += \"Non disponible\"\n        html_output += \"</td></tr>\"\n        \n        html_output += \"</table><br><hr><br>\"\n    \n    # Affichage du tableau HTML\n    display(HTML(html_output))\n    \n    # G√©n√©rer quelques statistiques\n    print(\"Statistiques sur les CV analys√©s:\")\n    print(f\"Nombre total de CV: {len(results)}\")\n    \n    # Calculer le nombre moyen d'exp√©riences par CV\n    avg_exp = sum(len(r['experiences']) for r in results) / len(results) if results else 0\n    print(f\"Nombre moyen d'exp√©riences professionnelles par CV: {avg_exp:.2f}\")\n    \n    # Calculer le nombre moyen de formations par CV\n    avg_form = sum(len(r['formations']) for r in results) / len(results) if results else 0\n    print(f\"Nombre moyen de formations par CV: {avg_form:.2f}\")\n    \n    # Calculer le nombre moyen de comp√©tences par CV\n    avg_comp = sum(len(r['competences']) for r in results) / len(results) if results else 0\n    print(f\"Nombre moyen de comp√©tences par CV: {avg_comp:.2f}\")\nelse:\n    print(\"Aucun CV n'a pu √™tre analys√©. V√©rifiez le chemin du dossier et le format des fichiers.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T00:20:05.116413Z","iopub.execute_input":"2025-03-21T00:20:05.116743Z","iopub.status.idle":"2025-03-21T00:20:47.223840Z","shell.execute_reply.started":"2025-03-21T00:20:05.116716Z","shell.execute_reply":"2025-03-21T00:20:47.222314Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2025.1.31)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\nRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.4->pandas) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.22.4->pandas) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.22.4->pandas) (2024.2.0)\nRequirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.8.3)\nCollecting google-generativeai\n  Downloading google_generativeai-0.8.4-py3-none-any.whl.metadata (4.2 kB)\nCollecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (1.34.1)\nRequirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.155.0)\nRequirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\nRequirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.11.0a2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.67.1)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.12.2)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.25.0)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.66.0)\nRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (2.32.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\nRequirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (2.29.0)\nRequirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.68.1)\nRequirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.48.2)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\nDownloading google_generativeai-0.8.4-py3-none-any.whl (175 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: google-ai-generativelanguage, google-generativeai\n  Attempting uninstall: google-ai-generativelanguage\n    Found existing installation: google-ai-generativelanguage 0.6.10\n    Uninstalling google-ai-generativelanguage-0.6.10:\n      Successfully uninstalled google-ai-generativelanguage-0.6.10\n  Attempting uninstall: google-generativeai\n    Found existing installation: google-generativeai 0.8.3\n    Uninstalling google-generativeai-0.8.3:\n      Successfully uninstalled google-generativeai-0.8.3\nSuccessfully installed google-ai-generativelanguage-0.6.15 google-generativeai-0.8.4\nTraitement du fichier: cvwail.pdf\nMod√®les disponibles:\n- models/chat-bison-001\n- models/text-bison-001\n- models/embedding-gecko-001\n- models/gemini-1.0-pro-vision-latest\n- models/gemini-pro-vision\n- models/gemini-1.5-pro-latest\n- models/gemini-1.5-pro-001\n- models/gemini-1.5-pro-002\n- models/gemini-1.5-pro\n- models/gemini-1.5-flash-latest\n- models/gemini-1.5-flash-001\n- models/gemini-1.5-flash-001-tuning\n- models/gemini-1.5-flash\n- models/gemini-1.5-flash-002\n- models/gemini-1.5-flash-8b\n- models/gemini-1.5-flash-8b-001\n- models/gemini-1.5-flash-8b-latest\n- models/gemini-1.5-flash-8b-exp-0827\n- models/gemini-1.5-flash-8b-exp-0924\n- models/gemini-2.0-flash-exp\n- models/gemini-2.0-flash\n- models/gemini-2.0-flash-001\n- models/gemini-2.0-flash-exp-image-generation\n- models/gemini-2.0-flash-lite-001\n- models/gemini-2.0-flash-lite\n- models/gemini-2.0-flash-lite-preview-02-05\n- models/gemini-2.0-flash-lite-preview\n- models/gemini-2.0-pro-exp\n- models/gemini-2.0-pro-exp-02-05\n- models/gemini-exp-1206\n- models/gemini-2.0-flash-thinking-exp-01-21\n- models/gemini-2.0-flash-thinking-exp\n- models/gemini-2.0-flash-thinking-exp-1219\n- models/learnlm-1.5-pro-experimental\n- models/gemma-3-27b-it\n- models/embedding-001\n- models/text-embedding-004\n- models/gemini-embedding-exp-03-07\n- models/gemini-embedding-exp\n- models/aqa\n- models/imagen-3.0-generate-002\nAucun mod√®le trouv√©, tentative avec: models/gemini-1.5-pro\n\n--- R√©sultats pour cvwail.pdf ---\nFormations: [{'diplome': 'Master MIAGE IA2', 'etablissement': 'Universit√© C√¥te d‚ÄôAzure', 'dates': 'Octobre 2024'}, {'diplome': \"Dipl√¥me d'ing√©nieur en informatique et r√©seaux\", 'etablissement': \"√âcole Marocaine des Sciences de l'Ing√©nieur\", 'dates': '2020-2025'}, {'diplome': 'Bac Sciences Physiques', 'etablissement': 'Lyc√©e scientifique Tour Hassan', 'dates': '2019-2020'}, {'diplome': 'Oracle Database Administration I', 'etablissement': None, 'dates': '2024'}, {'diplome': 'ing√©nierie logicielle', 'etablissement': None, 'dates': '2023'}, {'diplome': 'Python for everybody', 'etablissement': 'University of Michigan', 'dates': '2023'}, {'diplome': 'React Basics', 'etablissement': None, 'dates': '2023'}, {'diplome': 'Unix System Basics', 'etablissement': None, 'dates': '2023'}]\nExp√©riences: [{'poste': 'Stage de fin d‚Äôann√©e', 'entreprise': 'ECONOCOM', 'dates': '07/2023-08/2023', 'description': 'Application Web de Gestion des Cong√©s'}, {'poste': 'Stage de fin d‚Äôann√©e', 'entreprise': 'DIRHAM EXPRESS', 'dates': '07/2024-08/2024', 'description': 'Application Web de Gestion des employ√©s et stocks'}]\nComp√©tences: ['Langages de Programmation : C, C++, Java, Python, C#', 'Frameworks : Django, Fast API, .NET, Spring Boot, JEE', 'Bases de Donn√©es : SQL, T-SQL, PL/SQL, MySQL Server, Oracle', 'Outils ETL : Talend Open Studio', 'Big Data : Hadoop MapReduce, Pig, Hive, Microsoft Azure', 'Conception et Mod√©lisation : Merise, UML', 'D√©veloppement Mobile : Android Studio', 'Mod√©lisation des syst√®mes logiciels a l‚Äôaide de l‚ÄôUML']\nLangues: [{'langue': 'Anglais', 'niveau': 'C1'}, {'langue': 'Fran√ßais', 'niveau': 'C1'}, {'langue': 'Arabe', 'niveau': 'langue maternelle'}]\n\n--------------------------------------------------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"     filename                                         formations  \\\n0  cvwail.pdf  [{'diplome': 'Master MIAGE IA2', 'etablissemen...   \n\n                                         experiences  \\\n0  [{'poste': 'Stage de fin d‚Äôann√©e', 'entreprise...   \n\n                                         competences  \\\n0  [Langages de Programmation : C, C++, Java, Pyt...   \n\n                                             langues  \n0  [{'langue': 'Anglais', 'niveau': 'C1'}, {'lang...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>formations</th>\n      <th>experiences</th>\n      <th>competences</th>\n      <th>langues</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cvwail.pdf</td>\n      <td>[{'diplome': 'Master MIAGE IA2', 'etablissemen...</td>\n      <td>[{'poste': 'Stage de fin d‚Äôann√©e', 'entreprise...</td>\n      <td>[Langages de Programmation : C, C++, Java, Pyt...</td>\n      <td>[{'langue': 'Anglais', 'niveau': 'C1'}, {'lang...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<h2>Analyse d√©taill√©e des CV</h2><h3>CV: cvwail.pdf</h3><table border='1' width='100%'><tr><th>Cat√©gorie</th><th>D√©tails</th></tr><tr><td style='width:20%; font-weight:bold; vertical-align:top;'>Formations</td><td><ul><li>{'diplome': 'Master MIAGE IA2', 'etablissement': 'Universit√© C√¥te d‚ÄôAzure', 'dates': 'Octobre 2024'}</li><li>{'diplome': \"Dipl√¥me d'ing√©nieur en informatique et r√©seaux\", 'etablissement': \"√âcole Marocaine des Sciences de l'Ing√©nieur\", 'dates': '2020-2025'}</li><li>{'diplome': 'Bac Sciences Physiques', 'etablissement': 'Lyc√©e scientifique Tour Hassan', 'dates': '2019-2020'}</li><li>{'diplome': 'Oracle Database Administration I', 'etablissement': None, 'dates': '2024'}</li><li>{'diplome': 'ing√©nierie logicielle', 'etablissement': None, 'dates': '2023'}</li><li>{'diplome': 'Python for everybody', 'etablissement': 'University of Michigan', 'dates': '2023'}</li><li>{'diplome': 'React Basics', 'etablissement': None, 'dates': '2023'}</li><li>{'diplome': 'Unix System Basics', 'etablissement': None, 'dates': '2023'}</li></ul></td></tr><tr><td style='font-weight:bold; vertical-align:top;'>Exp√©riences</td><td><ul><li>{'poste': 'Stage de fin d‚Äôann√©e', 'entreprise': 'ECONOCOM', 'dates': '07/2023-08/2023', 'description': 'Application Web de Gestion des Cong√©s'}</li><li>{'poste': 'Stage de fin d‚Äôann√©e', 'entreprise': 'DIRHAM EXPRESS', 'dates': '07/2024-08/2024', 'description': 'Application Web de Gestion des employ√©s et stocks'}</li></ul></td></tr><tr><td style='font-weight:bold; vertical-align:top;'>Comp√©tences</td><td><ul><li>Langages de Programmation : C, C++, Java, Python, C#</li><li>Frameworks : Django, Fast API, .NET, Spring Boot, JEE</li><li>Bases de Donn√©es : SQL, T-SQL, PL/SQL, MySQL Server, Oracle</li><li>Outils ETL : Talend Open Studio</li><li>Big Data : Hadoop MapReduce, Pig, Hive, Microsoft Azure</li><li>Conception et Mod√©lisation : Merise, UML</li><li>D√©veloppement Mobile : Android Studio</li><li>Mod√©lisation des syst√®mes logiciels a l‚Äôaide de l‚ÄôUML</li></ul></td></tr><tr><td style='font-weight:bold; vertical-align:top;'>Langues</td><td><ul><li>{'langue': 'Anglais', 'niveau': 'C1'}</li><li>{'langue': 'Fran√ßais', 'niveau': 'C1'}</li><li>{'langue': 'Arabe', 'niveau': 'langue maternelle'}</li></ul></td></tr></table><br><hr><br>"},"metadata":{}},{"name":"stdout","text":"Statistiques sur les CV analys√©s:\nNombre total de CV: 1\nNombre moyen d'exp√©riences professionnelles par CV: 2.00\nNombre moyen de formations par CV: 8.00\nNombre moyen de comp√©tences par CV: 8.00\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"!pip install pymupdf google-generativeai\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T00:02:00.613356Z","iopub.execute_input":"2025-03-21T00:02:00.613673Z","iopub.status.idle":"2025-03-21T00:02:05.877032Z","shell.execute_reply.started":"2025-03-21T00:02:00.613646Z","shell.execute_reply":"2025-03-21T00:02:05.876048Z"}},"outputs":[{"name":"stdout","text":"Collecting pymupdf\n  Downloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\nRequirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.8.3)\nRequirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.6.10)\nRequirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (1.34.1)\nRequirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.155.0)\nRequirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\nRequirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.11.0a2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.67.1)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.12.2)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai) (1.25.0)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.66.0)\nRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (2.32.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\nRequirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (2.29.0)\nRequirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.68.1)\nRequirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.48.2)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\nDownloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pymupdf\nSuccessfully installed pymupdf-1.25.4\n","output_type":"stream"}],"execution_count":7}]}