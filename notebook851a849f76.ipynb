{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11042941,"sourceType":"datasetVersion","datasetId":6878875},{"sourceId":11095327,"sourceType":"datasetVersion","datasetId":6916517}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pdfplumber\n\npdf_path = \"/kaggle/input/cvvvvvvvvvv/cvwail.pdf\"\nwith pdfplumber.open(pdf_path) as pdf:\n    text = \"\\n\".join([page.extract_text() for page in pdf.pages if page.extract_text()])\nprint(text)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T18:21:46.734525Z","iopub.execute_input":"2025-03-15T18:21:46.734910Z","iopub.status.idle":"2025-03-15T18:21:47.253302Z","shell.execute_reply.started":"2025-03-15T18:21:46.734863Z","shell.execute_reply":"2025-03-15T18:21:47.252273Z"}},"outputs":[{"name":"stdout","text":"WAIL BENHARRATS\nFutur ingénieur en informatique option\nMIAGE à l’EMSI à la recherche d’un stage\nPFE à partir du mois de mars\nformation Academique\nOctobre 2024\nCONTACT\nMaster MIAGE IA2 Université Côte d’Azure\n0661990707 2020-2025\nDiplôme d'ingénieur en informatique et réseaux\nbenharatswail@gmail.com\nÉcole Marocaine des Sciences de l'Ingénieur\nRabat, Maroc\n2019-2020\nWail Benharrats Bac Sciences Physiques\nCertifications Lycée scientifique Tour Hassan\nExpérience professionnelle\nOracle Database Administration I\n(2024)\n07/2023-08/2023 - Stage de fin d’année\ningénierie logicielle (2023)\nModélisation des systèmes Entreprise ECONOCOM\nlogiciels a l’aide de l’UML\nApplication Web de Gestion des Congés\nPython for everybody - University of\nMichigan (2023) Conception et développement complet d'une application web de\ngestion des congés utilisant FastAPI, un framework Python pour\nReact Basics (2023)\nles API web.\nUnix System Basics (2023)\nDéveloppement des fonctionnalités de gestion des demandes\nde congés, de suivi des congés disponibles, et de génération de\nProjets academiques rapports pour les employés et les managers.\nProjet Fin d’année de la 4eme année 07/2024-08/2024 - Stage de de fin d’année\nRéalisation d’une application web\nEntreprise DIRHAM EXPRESS\nd’archivage en utilisant Spring Boot\nApplication Web de Gestion des employés et stocks\nProjet Fin d’année de la 3eme année\nRéalisation d’une application web de Conception et développement complet d'une application web de\ngestion d'école en utilisant Django gestion des employés et stocks en utilisant Django et en intégrant\ndans le projet la reconnaissance faciale et les détection des objets .\nLangues Connaissances techniques\nLangages de Programmation : C,C++, Java, Python, C#\nAnglais : niveau c1\nFrameworks : Django,Fast API,.NET,Spring Boot,JEE\nFrançais : niveau c1\nBases de Données : SQL, T-SQL, PL/SQL, MySQL Server,\nArabe : langue maternelle\nOracle\nOutils ETL : Talend Open Studio\nCentre d’intérêts\nBig Data : Hadoop MapReduce,Pig,Hive, Microsoft Azure\nSport\nConception et Modélisation : Merise, UML\nSuivi des tendances technologiques\nDéveloppement Mobile : Android Studio\nbénévolat\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import re\n\n# Suppression des caractères spéciaux et multiples espaces\ncleaned_text = re.sub(r'\\s+', ' ', text).strip()\nprint(cleaned_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T18:21:59.401361Z","iopub.execute_input":"2025-03-15T18:21:59.401792Z","iopub.status.idle":"2025-03-15T18:21:59.406824Z","shell.execute_reply.started":"2025-03-15T18:21:59.401765Z","shell.execute_reply":"2025-03-15T18:21:59.405721Z"}},"outputs":[{"name":"stdout","text":"WAIL BENHARRATS Futur ingénieur en informatique option MIAGE à l’EMSI à la recherche d’un stage PFE à partir du mois de mars formation Academique Octobre 2024 CONTACT Master MIAGE IA2 Université Côte d’Azure 0661990707 2020-2025 Diplôme d'ingénieur en informatique et réseaux benharatswail@gmail.com École Marocaine des Sciences de l'Ingénieur Rabat, Maroc 2019-2020 Wail Benharrats Bac Sciences Physiques Certifications Lycée scientifique Tour Hassan Expérience professionnelle Oracle Database Administration I (2024) 07/2023-08/2023 - Stage de fin d’année ingénierie logicielle (2023) Modélisation des systèmes Entreprise ECONOCOM logiciels a l’aide de l’UML Application Web de Gestion des Congés Python for everybody - University of Michigan (2023) Conception et développement complet d'une application web de gestion des congés utilisant FastAPI, un framework Python pour React Basics (2023) les API web. Unix System Basics (2023) Développement des fonctionnalités de gestion des demandes de congés, de suivi des congés disponibles, et de génération de Projets academiques rapports pour les employés et les managers. Projet Fin d’année de la 4eme année 07/2024-08/2024 - Stage de de fin d’année Réalisation d’une application web Entreprise DIRHAM EXPRESS d’archivage en utilisant Spring Boot Application Web de Gestion des employés et stocks Projet Fin d’année de la 3eme année Réalisation d’une application web de Conception et développement complet d'une application web de gestion d'école en utilisant Django gestion des employés et stocks en utilisant Django et en intégrant dans le projet la reconnaissance faciale et les détection des objets . Langues Connaissances techniques Langages de Programmation : C,C++, Java, Python, C# Anglais : niveau c1 Frameworks : Django,Fast API,.NET,Spring Boot,JEE Français : niveau c1 Bases de Données : SQL, T-SQL, PL/SQL, MySQL Server, Arabe : langue maternelle Oracle Outils ETL : Talend Open Studio Centre d’intérêts Big Data : Hadoop MapReduce,Pig,Hive, Microsoft Azure Sport Conception et Modélisation : Merise, UML Suivi des tendances technologiques Développement Mobile : Android Studio bénévolat\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import spacy\n\n# Charger le modèle français de spaCy\nnlp = spacy.load(\"fr_core_news_sm\")  \n\ndoc = nlp(cleaned_text)\nfor ent in doc.ents:\n    print(f\"{ent.label_}: {ent.text}\")  # Afficher les entités reconnues\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T18:23:43.391945Z","iopub.execute_input":"2025-03-15T18:23:43.392306Z","iopub.status.idle":"2025-03-15T18:23:49.362687Z","shell.execute_reply.started":"2025-03-15T18:23:43.392277Z","shell.execute_reply":"2025-03-15T18:23:49.357523Z"}},"outputs":[{"name":"stdout","text":"MISC: WAIL BENHARRATS Futur\nORG: l’EMSI\nMISC: PFE\nLOC: Diplôme\nORG: École Marocaine des Sciences de l'Ingénieur Rabat\nLOC: Maroc\nORG: Sciences Physiques\nMISC: Tour Hassan\nMISC: Entreprise\nMISC: ECONOCOM\nLOC: l’\nLOC: l’\nPER: Gestion des\nMISC: Python for everybody\nPER: Conception\nMISC: FastAPI\nMISC: Python\nPER: React Basics\nMISC: Unix System Basics\nLOC: Projets\nMISC: Réalisation\nMISC: Entreprise DIRHAM EXPRESS d’\nPER: Spring\nMISC: Application Web\nPER: Gestion\nMISC: Réalisation\nPER: Conception\nLOC: Django\nLOC: Django\nMISC: Langues Connaissances techniques Langages de Programmation :\nMISC: C++\nMISC: Java\nMISC: Python\nMISC: C#\nMISC: Anglais\nMISC: c1 Frameworks : Django\nPER: Fast API,\nMISC: NET\nMISC: Spring Boot\nMISC: JEE Français\nORG: c1 Bases\nLOC: Données\nMISC: SQL\nMISC: T-SQL\nMISC: PL/SQL\nMISC: MySQL Server\nMISC: Arabe\nPER: Oracle Outils ETL\nPER: Hadoop MapReduce\nLOC: Pig\nMISC: Hive\nORG: Microsoft\nLOC: Modélisation\nMISC: Développement Mobile\nMISC: Android Studio bénévolat\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Définition de regex pour identifier les sections spécifiques\nlangues_pattern = r\"(Langues|Langage(s)? :?)(.*)\"\nformations_pattern = r\"(Formation(s)?|Diplôme(s)? :?)(.*)\"\ncompetences_pattern = r\"(Compétences|Technologies|Logiciels :?)(.*)\"\n\n# Recherche des correspondances dans le texte\nlangues = re.findall(langues_pattern, cleaned_text, re.IGNORECASE)\nformations = re.findall(formations_pattern, cleaned_text, re.IGNORECASE)\ncompetences = re.findall(competences_pattern, cleaned_text, re.IGNORECASE)\n\nprint(\"Langues:\", langues)\nprint(\"Formations:\", formations)\nprint(\"Compétences:\", competences)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T18:25:15.216904Z","iopub.execute_input":"2025-03-15T18:25:15.217328Z","iopub.status.idle":"2025-03-15T18:25:15.226378Z","shell.execute_reply.started":"2025-03-15T18:25:15.217298Z","shell.execute_reply":"2025-03-15T18:25:15.225310Z"}},"outputs":[{"name":"stdout","text":"Langues: [('Langues', '', ' Connaissances techniques Langages de Programmation : C,C++, Java, Python, C# Anglais : niveau c1 Frameworks : Django,Fast API,.NET,Spring Boot,JEE Français : niveau c1 Bases de Données : SQL, T-SQL, PL/SQL, MySQL Server, Arabe : langue maternelle Oracle Outils ETL : Talend Open Studio Centre d’intérêts Big Data : Hadoop MapReduce,Pig,Hive, Microsoft Azure Sport Conception et Modélisation : Merise, UML Suivi des tendances technologiques Développement Mobile : Android Studio bénévolat')]\nFormations: [('formation', '', '', \" Academique Octobre 2024 CONTACT Master MIAGE IA2 Université Côte d’Azure 0661990707 2020-2025 Diplôme d'ingénieur en informatique et réseaux benharatswail@gmail.com École Marocaine des Sciences de l'Ingénieur Rabat, Maroc 2019-2020 Wail Benharrats Bac Sciences Physiques Certifications Lycée scientifique Tour Hassan Expérience professionnelle Oracle Database Administration I (2024) 07/2023-08/2023 - Stage de fin d’année ingénierie logicielle (2023) Modélisation des systèmes Entreprise ECONOCOM logiciels a l’aide de l’UML Application Web de Gestion des Congés Python for everybody - University of Michigan (2023) Conception et développement complet d'une application web de gestion des congés utilisant FastAPI, un framework Python pour React Basics (2023) les API web. Unix System Basics (2023) Développement des fonctionnalités de gestion des demandes de congés, de suivi des congés disponibles, et de génération de Projets academiques rapports pour les employés et les managers. Projet Fin d’année de la 4eme année 07/2024-08/2024 - Stage de de fin d’année Réalisation d’une application web Entreprise DIRHAM EXPRESS d’archivage en utilisant Spring Boot Application Web de Gestion des employés et stocks Projet Fin d’année de la 3eme année Réalisation d’une application web de Conception et développement complet d'une application web de gestion d'école en utilisant Django gestion des employés et stocks en utilisant Django et en intégrant dans le projet la reconnaissance faciale et les détection des objets . Langues Connaissances techniques Langages de Programmation : C,C++, Java, Python, C# Anglais : niveau c1 Frameworks : Django,Fast API,.NET,Spring Boot,JEE Français : niveau c1 Bases de Données : SQL, T-SQL, PL/SQL, MySQL Server, Arabe : langue maternelle Oracle Outils ETL : Talend Open Studio Centre d’intérêts Big Data : Hadoop MapReduce,Pig,Hive, Microsoft Azure Sport Conception et Modélisation : Merise, UML Suivi des tendances technologiques Développement Mobile : Android Studio bénévolat\")]\nCompétences: [('logiciels ', \"a l’aide de l’UML Application Web de Gestion des Congés Python for everybody - University of Michigan (2023) Conception et développement complet d'une application web de gestion des congés utilisant FastAPI, un framework Python pour React Basics (2023) les API web. Unix System Basics (2023) Développement des fonctionnalités de gestion des demandes de congés, de suivi des congés disponibles, et de génération de Projets academiques rapports pour les employés et les managers. Projet Fin d’année de la 4eme année 07/2024-08/2024 - Stage de de fin d’année Réalisation d’une application web Entreprise DIRHAM EXPRESS d’archivage en utilisant Spring Boot Application Web de Gestion des employés et stocks Projet Fin d’année de la 3eme année Réalisation d’une application web de Conception et développement complet d'une application web de gestion d'école en utilisant Django gestion des employés et stocks en utilisant Django et en intégrant dans le projet la reconnaissance faciale et les détection des objets . Langues Connaissances techniques Langages de Programmation : C,C++, Java, Python, C# Anglais : niveau c1 Frameworks : Django,Fast API,.NET,Spring Boot,JEE Français : niveau c1 Bases de Données : SQL, T-SQL, PL/SQL, MySQL Server, Arabe : langue maternelle Oracle Outils ETL : Talend Open Studio Centre d’intérêts Big Data : Hadoop MapReduce,Pig,Hive, Microsoft Azure Sport Conception et Modélisation : Merise, UML Suivi des tendances technologiques Développement Mobile : Android Studio bénévolat\")]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import re\nimport spacy\nimport pandas as pd\nfrom PyPDF2 import PdfReader\nfrom pathlib import Path\n\n# Paramètres à modifier\ndossier_cv = \"/kaggle/input/cvvvvvvvvvvvvvvvvv\"  # <-- Changez ce chemin vers votre dossier contenant les CV au format PDF\n\n# Installation et chargement du modèle spaCy français\ntry:\n    nlp = spacy.load(\"fr_core_news_md\")\nexcept:\n    print(\"Installation du modèle français SpaCy...\")\n    import os\n    os.system(\"python -m spacy download fr_core_news_md\")\n    nlp = spacy.load(\"fr_core_news_md\")\n\n# Définition des mots-clés et patterns\nsection_patterns = {\n    'formations': r'formations?|éducations?|diplômes?|cursus|études',\n    'compétences': r'compétences?|savoir.faire|expertises?|qualifications|technologies|outils|langages',\n    'experiences': r'expériences?|parcours|postes?|emplois?',\n    'langues': r'langues?|linguistiques?',\n}\n\neducation_keywords = [\n    'bac', 'licence', 'master', 'doctorat', 'diplôme', 'université',\n    'école', 'institut', 'ingénieur', 'formation', 'certificat'\n]\n\ntech_skills = [\n    'python', 'java', 'c++', 'javascript', 'html', 'css', 'sql', 'nosql',\n    'machine learning', 'deep learning', 'nlp', 'tensorflow', 'pytorch',\n    'scikit-learn', 'pandas', 'numpy', 'data mining', 'visualisation',\n    'cloud', 'aws', 'azure', 'gcp', 'devops', 'ci/cd', 'docker', 'kubernetes',\n    'git', 'agile', 'scrum', 'jira', 'confluence'\n]\n\n# Liste des fichiers PDF dans le dossier\ndossier = Path(dossier_cv)\npdf_files = list(dossier.glob(\"*.pdf\"))\nprint(f\"Traitement de {len(pdf_files)} fichiers PDF...\")\n\n# Liste pour stocker les résultats\nresultats = []\n\n# Traitement de chaque fichier PDF\nfor pdf_file in pdf_files:\n    print(f\"Analyse de: {pdf_file.name}\")\n    \n    # Extraction du texte\n    try:\n        reader = PdfReader(pdf_file)\n        texte = \"\"\n        for page in reader.pages:\n            texte += page.extract_text() + \"\\n\"\n    except Exception as e:\n        print(f\"Erreur lors de l'extraction du texte PDF: {e}\")\n        continue\n    \n    # Prétraitement du texte\n    texte = re.sub(r'\\s+', ' ', texte)  # Normaliser les espaces\n    texte = re.sub(r'[^\\w\\s.,;:()\\/\\-\\'\\\"]+', ' ', texte)  # Supprimer caractères spéciaux\n    texte = texte.strip()\n    \n    # Identification des sections\n    sections = {}\n    lignes = texte.split('\\n')\n    section_courante = 'unknown'\n    \n    for ligne in lignes:\n        ligne_lower = ligne.lower()\n        \n        # Vérifier si cette ligne correspond à un titre de section\n        for section, pattern in section_patterns.items():\n            if re.search(pattern, ligne_lower):\n                section_courante = section\n                sections[section_courante] = []\n                break\n        \n        # Ajouter la ligne à la section courante\n        if section_courante in sections:\n            sections[section_courante].append(ligne)\n    \n    # Texte pour chaque section\n    formation_text = '\\n'.join(sections.get('formations', []))\n    competences_text = '\\n'.join(sections.get('compétences', []))\n    langues_text = '\\n'.join(sections.get('langues', []))\n    \n    # Si les sections n'ont pas été identifiées, utiliser tout le texte\n    if not formation_text:\n        formation_text = texte\n    if not competences_text:\n        competences_text = texte\n    if not langues_text:\n        langues_text = texte\n    \n    # Extraction des formations\n    doc_formation = nlp(formation_text)\n    formations = []\n    \n    for sent in doc_formation.sents:\n        sent_text = sent.text.lower()\n        is_education = any(keyword in sent_text for keyword in education_keywords)\n        \n        if is_education:\n            # Extraire les dates\n            dates = re.findall(r'\\b(19|20)\\d{2}\\b', sent.text)\n            \n            # Extraire les entités nommées (écoles, universités)\n            org_names = [ent.text for ent in sent.ents if ent.label_ in [\"ORG\", \"LOC\"]]\n            \n            formations.append(sent.text.strip())\n    \n    # Extraction des compétences techniques\n    comp_text_lower = competences_text.lower()\n    competences_tech = [skill for skill in tech_skills if re.search(r'\\b' + re.escape(skill) + r'\\b', comp_text_lower)]\n    \n    # Extraction d'autres compétences potentielles\n    doc_comp = nlp(competences_text)\n    autres_comp = []\n    for token in doc_comp:\n        if token.pos_ in [\"NOUN\", \"PROPN\", \"ADJ\"] and len(token.text) > 3:\n            # Exclure les mots communs\n            if token.text.lower() not in [\"année\", \"expérience\", \"poste\", \"travail\", \"projet\"]:\n                autres_comp.append(token.text)\n    \n    # Déduplication et nettoyage des compétences\n    autres_comp = list(set(autres_comp))[:15]  # Limiter pour éviter le bruit\n    \n    # Extraction des langues\n    langues = [\"français\", \"anglais\", \"espagnol\", \"allemand\", \"italien\", \"chinois\", \"arabe\", \"russe\", \"portugais\", \"japonais\"]\n    niveaux = [\"courant\", \"bilingue\", \"natif\", \"professionnel\", \"intermédiaire\", \"débutant\", \"scolaire\", \"avancé\", \"b1\", \"b2\", \"c1\", \"c2\", \"a1\", \"a2\"]\n    \n    langues_detectees = {}\n    for langue in langues:\n        # Chercher la langue mentionnée avec son niveau potentiel\n        pattern = r'\\b' + langue + r'\\b.*?(' + '|'.join(niveaux) + r')\\b|(' + '|'.join(niveaux) + r')\\b.*?\\b' + langue + r'\\b'\n        match = re.search(pattern, langues_text.lower())\n        if match:\n            for niveau in niveaux:\n                if niveau in match.group(0):\n                    langues_detectees[langue] = niveau\n                    break\n        elif re.search(r'\\b' + langue + r'\\b', langues_text.lower()):\n            langues_detectees[langue] = \"mentionné\"\n    \n    # Préparation des résultats pour ce CV\n    resultats.append({\n        \"fichier\": pdf_file.name,\n        \"formations\": \", \".join(formations),\n        \"compétences_techniques\": \", \".join(competences_tech),\n        \"autres_compétences\": \", \".join(autres_comp),\n        \"langues\": \", \".join([f\"{langue} ({niveau})\" for langue, niveau in langues_detectees.items()])\n    })\n\n# Création et affichage du DataFrame\nif resultats:\n    df = pd.DataFrame(resultats)\n    \n    # Configuration pour un meilleur affichage\n    pd.set_option('display.max_columns', None)\n    pd.set_option('display.width', None)\n    pd.set_option('display.max_colwidth', None)\n    \n    # Affichage du DataFrame\n    print(\"\\n========== RÉSULTATS DE L'ANALYSE ==========\\n\")\n    print(df)\nelse:\n    print(\"Aucun résultat n'a été extrait.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T01:14:05.722121Z","iopub.execute_input":"2025-03-20T01:14:05.722530Z","iopub.status.idle":"2025-03-20T01:14:21.692029Z","shell.execute_reply.started":"2025-03-20T01:14:05.722500Z","shell.execute_reply":"2025-03-20T01:14:21.690373Z"}},"outputs":[{"name":"stdout","text":"Installation du modèle français SpaCy...\nTraitement de 1 fichiers PDF...\nAnalyse de: 208-modele-cv-informatique.pdf\n\n========== RÉSULTATS DE L'ANALYSE ==========\n\n                          fichier  \\\n0  208-modele-cv-informatique.pdf   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       formations  \\\n0  -curriculum.com FORMATION INFORMATICIEN, Web   EDF 20XX   20XX Ville, Pays   Développement front ou back en JavaScript., Université ou école   Ville,, Université ou école   Ville, Pays 20XX   20XX, BACCAULAURÉAT, GÉNÉRAL Université ou école   Ville, Pays 20XX   20XX, Ces documents, ou toute partie de ceux -ci ne peuvent être copiés, reproduits, distribués, utilisés ou réaffic hés dans d'autres sites web sans le consentement préalable et écrit d AZURIUS S.L. N'oubliez pas de supprimer cette information copyright avant de modifier et d'imprimer votre CV.   \n\n     compétences_techniques  \\\n0  python, javascript, html   \n\n                                                                                                                                    autres_compétences  \\\n0  HTML, Créez, Espagnol, marketing, Motivation, France, curriculum.com, outil, applications, LIRE, réalisation, Europe, Sport, communication, GÉNÉRAL   \n\n                                                            langues  \n0  français (mentionné), espagnol (mentionné), allemand (mentionné)  \n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!pip install PyPDF2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T23:51:11.604459Z","iopub.execute_input":"2025-03-15T23:51:11.604869Z","iopub.status.idle":"2025-03-15T23:51:18.055068Z","shell.execute_reply.started":"2025-03-15T23:51:11.604840Z","shell.execute_reply":"2025-03-15T23:51:18.053661Z"}},"outputs":[{"name":"stdout","text":"Collecting PyPDF2\n  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\nDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: PyPDF2\nSuccessfully installed PyPDF2-3.0.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import spacy\nfrom PyPDF2 import PdfReader\nimport re\n\n# Charger le modèle spaCy (version grande pour plus de précision)\nnlp = spacy.load(\"fr_core_news_lg\")\n\n# Liste de compétences techniques (à adapter selon vos besoins)\nCOMPETENCES_TECHNIQUES = [\n    \"Python\", \"Java\", \"Machine Learning\", \"SQL\", \"JavaScript\", \"React\", \"Angular\",\n    \"TensorFlow\", \"PyTorch\", \"Git\", \"Docker\", \"AWS\", \"Azure\", \"Linux\", \"HTML\", \"CSS\"\n]\n\n# Fonction pour extraire le texte d'un PDF\ndef extract_text_from_pdf(pdf_path):\n    try:\n        reader = PdfReader(pdf_path)\n        text = \"\"\n        for page in reader.pages:\n            text += page.extract_text()\n        return text\n    except Exception as e:\n        print(f\"Erreur lors de la lecture du PDF : {e}\")\n        return None\n\n# Fonction pour nettoyer le texte\ndef clean_text(text):\n    if text:\n        # Supprimer les sauts de ligne et les espaces multiples\n        text = re.sub(r'\\s+', ' ', text).strip()\n        return text\n    return None\n\n# Fonction pour extraire les formations\ndef extract_formations(text):\n    formations = []\n    # Exemple de motifs pour détecter les formations\n    patterns = [\n        r\"(Licence|Master|Baccalauréat|Doctorat|Diplôme|École|Université)[\\s\\w-]+\",\n        r\"\\b(?:Licence|Master|Bac|Doctorat|Diplôme)\\b[\\s\\w-]+\"\n    ]\n    for pattern in patterns:\n        matches = re.findall(pattern, text, re.IGNORECASE)\n        formations.extend(matches)\n    return list(set(formations))  # Supprimer les doublons\n\n# Fonction pour extraire les compétences\ndef extract_competences(text):\n    competences = []\n    # Rechercher les compétences techniques dans le texte\n    for competence in COMPETENCES_TECHNIQUES:\n        if competence.lower() in text.lower():\n            competences.append(competence)\n    return competences\n\n# Fonction pour extraire les langues\ndef extract_langues(text):\n    langues = []\n    # Exemple de motifs pour détecter les langues\n    patterns = [\n        r\"\\b(?:Anglais|Français|Espagnol|Allemand|Italien)\\b[\\s\\w-]*(?:courant|intermédiaire|débutant)?\",\n        r\"\\b(?:English|French|Spanish|German|Italian)\\b[\\s\\w-]*(?:fluent|intermediate|basic)?\"\n    ]\n    for pattern in patterns:\n        matches = re.findall(pattern, text, re.IGNORECASE)\n        langues.extend(matches)\n    return list(set(langues))  # Supprimer les doublons\n\n# Fonction principale pour extraire les informations\ndef extract_cv_info(pdf_path):\n    # Extraire le texte du PDF\n    text = extract_text_from_pdf(pdf_path)\n    if not text:\n        return None\n    \n    # Nettoyer le texte\n    text = clean_text(text)\n    \n    # Extraire les informations\n    formations = extract_formations(text)\n    competences = extract_competences(text)\n    langues = extract_langues(text)\n    \n    return {\n        \"formations\": formations,\n        \"competences\": competences,\n        \"langues\": langues\n    }\n\n# Exemple d'utilisation\npdf_path = \"/kaggle/input/cvvvvvvvvvvvvvvvvv/208-modele-cv-informatique.pdf\"\ncv_info = extract_cv_info(pdf_path)\n\nif cv_info:\n    print(\"Formations :\", cv_info[\"formations\"])\n    print(\"Compétences :\", cv_info[\"competences\"])\n    print(\"Langues :\", cv_info[\"langues\"])\nelse:\n    print(\"Erreur lors de l'extraction des informations.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T01:13:06.673099Z","iopub.execute_input":"2025-03-20T01:13:06.673500Z","iopub.status.idle":"2025-03-20T01:13:09.777234Z","shell.execute_reply.started":"2025-03-20T01:13:06.673470Z","shell.execute_reply":"2025-03-20T01:13:09.776429Z"}},"outputs":[{"name":"stdout","text":"Formations : ['Université']\nCompétences : ['Python', 'Java', 'JavaScript', 'HTML']\nLangues : ['Français Espagnol Allemand LANGUES CENTRES D']\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import fitz  # PyMuPDF pour lire les PDF\nimport spacy\nimport re\n\n# Télécharger le modèle français de spaCy si ce n'est pas fait\ntry:\n    nlp = spacy.load(\"fr_core_news_lg\")\nexcept OSError:\n    import subprocess\n    subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"fr_core_news_lg\"])\n    nlp = spacy.load(\"fr_core_news_lg\")\n\n\n# Fonction pour extraire le texte d'un PDF\ndef extract_text_from_pdf(pdf_path):\n    try:\n        doc = fitz.open(pdf_path)\n        text = \"\\n\".join([page.get_text(\"text\") for page in doc])\n        return text.strip()\n    except Exception as e:\n        print(f\"Erreur lors de la lecture du PDF : {e}\")\n        return None\n\n\n# Fonction pour analyser le texte et extraire les sections clés\ndef extract_cv_info(text):\n    sections = {\n        \"Nom\": \"\",\n        \"Email\": \"\",\n        \"Téléphone\": \"\",\n        \"Expériences\": \"\",\n        \"Formations\": \"\",\n        \"Compétences\": \"\",\n        \"Langues\": \"\"\n    }\n    \n    # Appliquer spaCy\n    doc = nlp(text)\n\n    # Extraction du nom (en supposant qu'il est en début de document)\n    if doc.ents:\n        sections[\"Nom\"] = doc.ents[0].text  # Premier entité (souvent le nom)\n\n    # Extraction des emails\n    email_match = re.search(r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\", text)\n    if email_match:\n        sections[\"Email\"] = email_match.group(0)\n\n    # Extraction du téléphone\n    phone_match = re.search(r\"\\+?\\d[\\d\\s.-]{8,}\", text)\n    if phone_match:\n        sections[\"Téléphone\"] = phone_match.group(0)\n\n    # Extraction des expériences professionnelles\n    exp_match = re.search(r\"(EXPÉRIENCES|EXPÉRIENCE|EXPERIENCE|TRAVAIL)\\s*:\\s*(.*?)(?:FORMATION|COMPÉTENCES|LANGUES)\", text, re.DOTALL | re.IGNORECASE)\n    if exp_match:\n        sections[\"Expériences\"] = exp_match.group(2).strip()\n\n    # Extraction des formations\n    formation_match = re.search(r\"(FORMATION|ÉDUCATION|DIPLÔMES)\\s*:\\s*(.*?)(?:EXPÉRIENCES|COMPÉTENCES|LANGUES)\", text, re.DOTALL | re.IGNORECASE)\n    if formation_match:\n        sections[\"Formations\"] = formation_match.group(2).strip()\n\n    # Extraction des compétences\n    competences_match = re.search(r\"(COMPÉTENCES|SKILLS)\\s*:\\s*(.*?)(?:EXPÉRIENCES|FORMATION|LANGUES)\", text, re.DOTALL | re.IGNORECASE)\n    if competences_match:\n        sections[\"Compétences\"] = competences_match.group(2).strip()\n\n    # Extraction des langues\n    langues_match = re.search(r\"(LANGUES|LANGUAGE)\\s*:\\s*(.*?)(?:EXPÉRIENCES|FORMATION|COMPÉTENCES)\", text, re.DOTALL | re.IGNORECASE)\n    if langues_match:\n        sections[\"Langues\"] = langues_match.group(2).strip()\n\n    return sections\n\n\n# Fonction principale\ndef process_cv(pdf_path):\n    # Extraire le texte\n    text = extract_text_from_pdf(pdf_path)\n    if not text:\n        return None\n\n    # Extraire les infos du CV\n    cv_info = extract_cv_info(text)\n    \n    return cv_info\n\n\n# 📄 Exemple d'utilisation\npdf_path = \"/kaggle/input/cvvvvvvvvvv/cvwail.pdf\"  # Remplace avec ton vrai fichier PDF\ncv_info = process_cv(pdf_path)\n\nif cv_info:\n    for key, value in cv_info.items():\n        print(f\"{key}: {value}\")\nelse:\n    print(\"Erreur lors de l'extraction des informations.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T02:04:17.316296Z","iopub.execute_input":"2025-03-20T02:04:17.316807Z","iopub.status.idle":"2025-03-20T02:04:20.927591Z","shell.execute_reply.started":"2025-03-20T02:04:17.316774Z","shell.execute_reply":"2025-03-20T02:04:20.926655Z"}},"outputs":[{"name":"stdout","text":"Nom: Expérience professionnelle\nCONTACT\nEmail: benharatswail@gmail.com\nTéléphone: 0661990707\n\nExpériences: \nFormations: \nCompétences: \nLangues: \n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"!pip install langchain langchain-community openai\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T01:31:43.297147Z","iopub.execute_input":"2025-03-20T01:31:43.297633Z","iopub.status.idle":"2025-03-20T01:31:55.110218Z","shell.execute_reply.started":"2025-03-20T01:31:43.297595Z","shell.execute_reply":"2025-03-20T01:31:55.108971Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.12)\nCollecting langchain-community\n  Downloading langchain_community-0.3.20-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.57.4)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.12)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\nRequirement already satisfied: langchain-core<0.4.0,>=0.3.25 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.25)\nRequirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.3)\nRequirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\nRequirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.11.0a2)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\nCollecting langchain-core<0.4.0,>=0.3.25 (from langchain)\n  Downloading langchain_core-0.3.46-py3-none-any.whl.metadata (5.9 kB)\nCollecting langchain\n  Downloading langchain-0.3.21-py3-none-any.whl.metadata (7.8 kB)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\nCollecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\nCollecting langchain-text-splitters<1.0.0,>=0.3.7 (from langchain)\n  Downloading langchain_text_splitters-0.3.7-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\nRequirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\nRequirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (24.2)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.29.0)\nCollecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.3.0)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.25->langchain) (3.0.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.22.4->langchain) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.22.4->langchain) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1.22.4->langchain) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2,>=1.22.4->langchain) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2,>=1.22.4->langchain) (2024.2.0)\nDownloading langchain_community-0.3.20-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain-0.3.21-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nDownloading langchain_core-0.3.46-py3-none-any.whl (417 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.1/417.1 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.3.7-py3-none-any.whl (32 kB)\nDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\nDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\nInstalling collected packages: python-dotenv, httpx-sse, pydantic-settings, langchain-core, langchain-text-splitters, langchain, langchain-community\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.25\n    Uninstalling langchain-core-0.3.25:\n      Successfully uninstalled langchain-core-0.3.25\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.3.3\n    Uninstalling langchain-text-splitters-0.3.3:\n      Successfully uninstalled langchain-text-splitters-0.3.3\n  Attempting uninstall: langchain\n    Found existing installation: langchain 0.3.12\n    Uninstalling langchain-0.3.12:\n      Successfully uninstalled langchain-0.3.12\nSuccessfully installed httpx-sse-0.4.0 langchain-0.3.21 langchain-community-0.3.20 langchain-core-0.3.46 langchain-text-splitters-0.3.7 pydantic-settings-2.8.1 python-dotenv-1.0.1\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"pip install PyPDF2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T13:28:31.010516Z","iopub.execute_input":"2025-03-20T13:28:31.010888Z","iopub.status.idle":"2025-03-20T13:28:37.209343Z","shell.execute_reply.started":"2025-03-20T13:28:31.010855Z","shell.execute_reply":"2025-03-20T13:28:37.207995Z"}},"outputs":[{"name":"stdout","text":"Collecting PyPDF2\n  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\nDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: PyPDF2\nSuccessfully installed PyPDF2-3.0.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pdfplumber\nfrom transformers import pipeline\n\n# 🔹 Extraction du texte du PDF\ndef extract_text_from_pdf(pdf_path):\n    with pdfplumber.open(pdf_path) as pdf:\n        return \"\\n\".join([page.extract_text() for page in pdf.pages if page.extract_text()])\n\n# 🔹 Chargement du modèle NER\nner_pipeline = pipeline(\"ner\", model=\"Jean-Baptiste/camembert-ner\", tokenizer=\"Jean-Baptiste/camembert-ner\", aggregation_strategy=\"simple\")\n\n# 🔹 Listes de contrôle pour classification\nFORMATION_KEYWORDS = [\"Université\", \"École\", \"Master\", \"Licence\", \"Bac\", \"Certification\", \"Doctorat\"]\nEXPERIENCE_EXCLUDE = [\"University\", \"École\", \"Institut\", \"College\"]\nCOMPETENCES_LIST = [\"Python\", \"Java\", \"Django\", \"SQL\", \"FastAPI\", \"React\", \"Machine Learning\", \"Deep Learning\", \"Hadoop\"]\nLANGUES_LIST = [\"Français\", \"Anglais\", \"Arabe\", \"Espagnol\", \"Allemand\"]\nLIEUX_LIST = [\"Maroc\", \"Rabat\", \"France\", \"Belgique\", \"Canada\"]  # Exclure des formations\n\n# 🔹 Fonction améliorée de classification\ndef categorize_entities(entities):\n    categories = {\n        \"Expériences\": [],\n        \"Formations\": [],\n        \"Compétences\": [],\n        \"Langues\": [],\n    }\n\n    for entity in entities:\n        text = entity[\"word\"]\n        label = entity[\"entity_group\"]\n\n        # 🔹 Correction des expériences\n        if label in [\"PER\", \"ORG\"]:\n            if any(word in text for word in EXPERIENCE_EXCLUDE):\n                categories[\"Formations\"].append(text)  \n            else:\n                categories[\"Expériences\"].append(text)\n\n        # 🔹 Correction des formations\n        elif label in [\"MISC\"]:\n            if text in LIEUX_LIST:  \n                continue  # Ignore les lieux\n            if any(word in text for word in FORMATION_KEYWORDS):\n                categories[\"Formations\"].append(text)\n            else:\n                categories[\"Compétences\"].append(text)\n\n        # 🔹 Correction des compétences\n        elif label in [\"LOC\"]:  \n            if text in COMPETENCES_LIST:\n                categories[\"Compétences\"].append(text)\n            else:\n                categories[\"Formations\"].append(text)\n\n        # 🔹 Ajout des langues\n        if text in LANGUES_LIST:\n            categories[\"Langues\"].append(text)\n\n    return {key: list(set(value)) for key, value in categories.items()}  # Suppression des doublons\n\n# 🔹 Fonction principale\ndef process_cv(pdf_path):\n    text = extract_text_from_pdf(pdf_path)\n    entities = ner_pipeline(text)\n    return categorize_entities(entities)\n\n# 🔥 Test avec un CV\ncv_path = \"/kaggle/input/cvvvvvvvvvv/cvwail.pdf\"\nresult = process_cv(cv_path)\nprint(result)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T12:08:02.896316Z","iopub.execute_input":"2025-03-20T12:08:02.896660Z","iopub.status.idle":"2025-03-20T12:08:04.461864Z","shell.execute_reply.started":"2025-03-20T12:08:02.896632Z","shell.execute_reply":"2025-03-20T12:08:04.460936Z"}},"outputs":[{"name":"stderr","text":"Device set to use cpu\n","output_type":"stream"},{"name":"stdout","text":"{'Expériences': ['EMSI', 'WAIL BENHARRATS', 'Wail Benharrats'], 'Formations': ['Université Côte d’Azure', 'University of Michigan', 'Maroc', \"École Marocaine des Sciences de l'Ingénieur\", 'Lycée scientifique Tour Hassan', 'Rabat'], 'Compétences': ['Django', 'Pig,Hive', 'UML', 'C# Anglais', 'web Entreprise DIRHAM EXPRESS', 'Data', 'Oracle Outils ETL', 'de Données', 'SQL', 'FastAPI', 'PL/SQL', 'Programmation', 'Arabe', 'MySQL Server', 'UML Application Web de Gestion des Congés Python for everybody', 'Projets academiques', 'Spring Boot Application Web de Gestion des employés et stocks', 'JEE Français', '.NET', 'Microsoft Azure Sport', 'Entreprise ECONOCOM', 'Talend Open Studio', 'Spring Boot', 'Python', 'Base', 'Mobile', 'Oracle Database Administration I', 'Hadoop MapReduce', 'C,C++', 'Unix System Basics', 'T-SQL', 'Fast API', 'React Basics', 'Java', 'Langages', 'Merise', 'Android Studio bénévolat'], 'Langues': ['Arabe']}\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Installer les bibliothèques nécessaires\n\n\n# Importer les bibliothèques\nimport PyPDF2\nimport json\nimport os\nimport requests\nimport pandas as pd\nfrom IPython.display import display, HTML\n\n# Configurer l'API key directement\nopenai_api_key = \"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\"  # Remplacez par votre clé API OpenAI réelle\n\n# Fonction pour extraire le texte du PDF\ndef extract_text_from_pdf(pdf_path):\n    with open(pdf_path, \"rb\") as file:\n        reader = PyPDF2.PdfReader(file)\n        text = \"\"\n        for page in reader.pages:\n            text += page.extract_text()\n    return text\n\n# Fonction pour analyser le CV avec une API\ndef analyze_cv(cv_text):\n    headers = {\n        \"Authorization\": f\"Bearer {openai_api_key}\",\n        \"Content-Type\": \"application/json\"\n    }\n    \n    data = {\n        \"model\": \"gpt-3.5-turbo\",  # Modèle modifié à gpt-3.5-turbo\n        \"messages\": [\n            {\n                \"role\": \"system\",\n                \"content\": \"Extrais les informations suivantes du CV: formations, expériences professionnelles, compétences, langues. Réponds uniquement en format JSON.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": cv_text\n            }\n        ]\n    }\n    \n    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=data)\n    return response.json()\n\n# Exemple d'utilisation\ncv_folder = \"/kaggle/input/cvvvvvvvvvv\"  # Chemin vers votre dossier de CVs\nresults = []\n\n# Analyser les CV\nfor filename in os.listdir(cv_folder)[:3]:  # Limite à 3 fichiers pour la démo\n    if filename.endswith(\".pdf\"):\n        pdf_path = os.path.join(cv_folder, filename)\n        print(f\"Traitement du fichier: {filename}\")\n        \n        cv_text = extract_text_from_pdf(pdf_path)\n        cv_data = analyze_cv(cv_text)\n        \n        # Extraire le contenu réel du JSON de la réponse de l'API\n        try:\n            # La structure exacte dépend de l'API que vous utilisez\n            content = json.loads(cv_data['choices'][0]['message']['content'])\n            \n            # Afficher les informations structurées\n            print(f\"\\n--- Résultats pour {filename} ---\")\n            print(f\"Formations: {content.get('formations', 'Non disponible')}\")\n            print(f\"Expériences: {content.get('expériences professionnelles', 'Non disponible')}\")\n            print(f\"Compétences: {content.get('compétences', 'Non disponible')}\")\n            print(f\"Langues: {content.get('langues', 'Non disponible')}\")\n            print(\"\\n\" + \"-\"*50 + \"\\n\")\n            \n            results.append({\n                \"filename\": filename,\n                \"formations\": content.get('formations', []),\n                \"experiences\": content.get('expériences professionnelles', []),\n                \"competences\": content.get('compétences', []),\n                \"langues\": content.get('langues', [])\n            })\n        except Exception as e:\n            print(f\"Erreur lors du traitement de {filename}: {e}\")\n            print(f\"Réponse brute: {cv_data}\")\n\n# Créer un DataFrame pour une visualisation plus structurée\nif results:\n    df = pd.DataFrame(results)\n    display(df)\n    \n    # Vous pouvez également créer un tableau HTML plus élaboré\n    html_output = \"<h2>Analyse détaillée des CV</h2>\"\n    for result in results:\n        html_output += f\"<h3>CV: {result['filename']}</h3>\"\n        html_output += \"<table border='1'>\"\n        html_output += \"<tr><th>Catégorie</th><th>Détails</th></tr>\"\n        html_output += f\"<tr><td>Formations</td><td>{result['formations']}</td></tr>\"\n        html_output += f\"<tr><td>Expériences</td><td>{result['experiences']}</td></tr>\"\n        html_output += f\"<tr><td>Compétences</td><td>{result['competences']}</td></tr>\"\n        html_output += f\"<tr><td>Langues</td><td>{result['langues']}</td></tr>\"\n        html_output += \"</table><br>\"\n    \n    display(HTML(html_output))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T15:01:24.585216Z","iopub.execute_input":"2025-03-20T15:01:24.585631Z","iopub.status.idle":"2025-03-20T15:01:26.056146Z","shell.execute_reply.started":"2025-03-20T15:01:24.585601Z","shell.execute_reply":"2025-03-20T15:01:26.055247Z"}},"outputs":[{"name":"stdout","text":"Traitement du fichier: cvwail.pdf\nErreur lors du traitement de cvwail.pdf: 'choices'\nRéponse brute: {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"pip install PyPDF2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T15:01:08.891277Z","iopub.execute_input":"2025-03-20T15:01:08.891625Z","iopub.status.idle":"2025-03-20T15:01:15.054669Z","shell.execute_reply.started":"2025-03-20T15:01:08.891601Z","shell.execute_reply":"2025-03-20T15:01:15.053511Z"}},"outputs":[{"name":"stdout","text":"Collecting PyPDF2\n  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\nDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: PyPDF2\nSuccessfully installed PyPDF2-3.0.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Installer les bibliothèques nécessaires\n!pip install PyPDF2\n!pip install requests\n!pip install pandas\n\n# Importer les bibliothèques\nimport PyPDF2\nimport requests\nimport json\nimport pandas as pd\nimport os\nfrom IPython.display import display, HTML\n\n# Configurer l'API key directement\nquen_api_key = \"votre-clé-api-quen-ici\"  # Remplacez par votre clé API Quen AI\n\n# Fonction pour extraire le texte du PDF\ndef extract_text_from_pdf(pdf_path):\n    with open(pdf_path, \"rb\") as file:\n        reader = PyPDF2.PdfReader(file)\n        text = \"\"\n        for page in reader.pages:\n            text += page.extract_text()\n    return text\n\n# Fonction pour analyser le CV avec l'API Quen AI\ndef analyze_cv_with_quen(cv_text):\n    headers = {\n        \"Content-Type\": \"application/json\",\n        \"Authorization\": f\"Bearer {quen_api_key}\"  # Authentification via Bearer Token\n    }\n    \n    # Structure de la requête pour Quen AI (à adapter selon la documentation)\n    data = {\n        \"text\": cv_text,  # Texte du CV\n        \"tasks\": [\"extract_formations\", \"extract_experiences\", \"extract_competences\", \"extract_langues\"],  # Tâches à effectuer\n        \"format\": \"json\"  # Format de la réponse\n    }\n    \n    # Endpoint de l'API Quen AI (à adapter selon la documentation)\n    response = requests.post(\"https://api.quen.ai/v1/analyze\", headers=headers, json=data)\n    return response.json()\n\n# Exemple d'utilisation\ncv_folder = \"/kaggle/input/cv-dataset/\"  # Chemin vers votre dossier de CVs\nresults = []\n\n# Analyser les CV\nfor filename in os.listdir(cv_folder):  # Traitez tous les fichiers\n    if filename.endswith(\".pdf\"):\n        pdf_path = os.path.join(cv_folder, filename)\n        print(f\"Traitement du fichier: {filename}\")\n        \n        cv_text = extract_text_from_pdf(pdf_path)\n        cv_data = analyze_cv_with_quen(cv_text)\n        \n        # Extraire le contenu réel du JSON de la réponse de l'API\n        try:\n            # La structure exacte dépend de l'API Quen AI\n            content = cv_data.get('results', {})\n            \n            # Afficher les informations structurées\n            print(f\"\\n--- Résultats pour {filename} ---\")\n            print(f\"Formations: {content.get('formations', 'Non disponible')}\")\n            print(f\"Expériences: {content.get('experiences', 'Non disponible')}\")\n            print(f\"Compétences: {content.get('competences', 'Non disponible')}\")\n            print(f\"Langues: {content.get('langues', 'Non disponible')}\")\n            print(\"\\n\" + \"-\"*50 + \"\\n\")\n            \n            results.append({\n                \"filename\": filename,\n                \"formations\": content.get('formations', []),\n                \"experiences\": content.get('experiences', []),\n                \"competences\": content.get('competences', []),\n                \"langues\": content.get('langues', [])\n            })\n        except Exception as e:\n            print(f\"Erreur lors du traitement de {filename}: {e}\")\n            print(f\"Réponse brute: {cv_data}\")\n\n# Créer un DataFrame pour une visualisation plus structurée\nif results:\n    # Création d'un DataFrame pour une vue d'ensemble\n    df = pd.DataFrame(results)\n    display(df)\n    \n    # Création d'une visualisation HTML plus détaillée\n    html_output = \"<h2>Analyse détaillée des CV</h2>\"\n    for result in results:\n        html_output += f\"<h3>CV: {result['filename']}</h3>\"\n        html_output += \"<table border='1' width='100%'>\"\n        html_output += \"<tr><th>Catégorie</th><th>Détails</th></tr>\"\n        \n        # Formations\n        html_output += \"<tr><td style='width:20%; font-weight:bold; vertical-align:top;'>Formations</td><td>\"\n        if result['formations']:\n            html_output += \"<ul>\"\n            for item in result['formations']:\n                html_output += f\"<li>{item}</li>\"\n            html_output += \"</ul>\"\n        else:\n            html_output += \"Non disponible\"\n        html_output += \"</td></tr>\"\n        \n        # Expériences\n        html_output += \"<tr><td style='font-weight:bold; vertical-align:top;'>Expériences</td><td>\"\n        if result['experiences']:\n            html_output += \"<ul>\"\n            for item in result['experiences']:\n                html_output += f\"<li>{item}</li>\"\n            html_output += \"</ul>\"\n        else:\n            html_output += \"Non disponible\"\n        html_output += \"</td></tr>\"\n        \n        # Compétences\n        html_output += \"<tr><td style='font-weight:bold; vertical-align:top;'>Compétences</td><td>\"\n        if result['competences']:\n            html_output += \"<ul>\"\n            for item in result['competences']:\n                html_output += f\"<li>{item}</li>\"\n            html_output += \"</ul>\"\n        else:\n            html_output += \"Non disponible\"\n        html_output += \"</td></tr>\"\n        \n        # Langues\n        html_output += \"<tr><td style='font-weight:bold; vertical-align:top;'>Langues</td><td>\"\n        if result['langues']:\n            html_output += \"<ul>\"\n            for item in result['langues']:\n                html_output += f\"<li>{item}</li>\"\n            html_output += \"</ul>\"\n        else:\n            html_output += \"Non disponible\"\n        html_output += \"</td></tr>\"\n        \n        html_output += \"</table><br><hr><br>\"\n    \n    # Affichage du tableau HTML\n    display(HTML(html_output))\n    \n    # Générer quelques statistiques\n    print(\"Statistiques sur les CV analysés:\")\n    print(f\"Nombre total de CV: {len(results)}\")\n    \n    # Calculer le nombre moyen d'expériences par CV\n    avg_exp = sum(len(r['experiences']) for r in results) / len(results) if results else 0\n    print(f\"Nombre moyen d'expériences professionnelles par CV: {avg_exp:.2f}\")\n    \n    # Calculer le nombre moyen de formations par CV\n    avg_form = sum(len(r['formations']) for r in results) / len(results) if results else 0\n    print(f\"Nombre moyen de formations par CV: {avg_form:.2f}\")\n    \n    # Calculer le nombre moyen de compétences par CV\n    avg_comp = sum(len(r['competences']) for r in results) / len(results) if results else 0\n    print(f\"Nombre moyen de compétences par CV: {avg_comp:.2f}\")\nelse:\n    print(\"Aucun CV n'a pu être analysé. Vérifiez le chemin du dossier et le format des fichiers.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T15:08:28.114788Z","iopub.execute_input":"2025-03-20T15:08:28.115427Z","iopub.status.idle":"2025-03-20T15:09:37.093744Z","shell.execute_reply.started":"2025-03-20T15:08:28.115388Z","shell.execute_reply":"2025-03-20T15:09:37.092576Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\nRequirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.11)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.5.0)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.15.1)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.67.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.11.0a2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.5.0)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.29.0)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spacy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spacy) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->spacy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.19.0->spacy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.19.0->spacy) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\nCollecting fr-core-news-lg==3.7.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_lg-3.7.0/fr_core_news_lg-3.7.0-py3-none-any.whl (571.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.8/571.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from fr-core-news-lg==3.7.0) (3.7.5)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (1.0.11)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2.0.10)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2.5.0)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (0.15.1)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (4.67.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2.11.0a2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (3.1.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (75.1.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (24.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (3.5.0)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2.29.0)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2025.1.31)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (13.9.4)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (7.0.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (3.0.2)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2.19.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.19.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-lg==3.7.0) (0.1.2)\nInstalling collected packages: fr-core-news-lg\nSuccessfully installed fr-core-news-lg-3.7.0\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('fr_core_news_lg')\n\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\nRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.4->pandas) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.22.4->pandas) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.22.4->pandas) (2024.2.0)\nTraitement du fichier: cvwail.pdf\n\n--- Résultats pour cvwail.pdf ---\nFormations: [\"Expérience professionnelleCONTACT\\nConception et développement complet d'une application web de\\ngestion des congés utilisant FastAPI, un framework Python pour\\nles API web.\\nDéveloppement des fonctionnalités de gestion des demandes\\nde congés, de suivi des congés disponibles, et de génération de\\nrapports pour les employés et les managers.\\nConception et développement complet d'une application web de\\ngestion des employés et stocks en utilisant Django et en intégrant\\ndans le projet la reconnaissance faciale et les détection des objets .\\nConnaissances techniques Projets academiquesformation Academique\\nCertifications\\nOracle Database Administration I\\n(2024)\\ningénierie logicielle (2023)\\n Modélisation des systèmes \\n logiciels a l’aide de l’UML\\nPython for everybody - University of\\nMichigan (2023)\\nReact Basics (2023)\\nUnix System Basics (2023)\\nLangues0661990707\\nbenharatswail@gmail.com\\nRabat, MarocWAIL BENHARRATS\\nFutur ingénieur en informatique option\\nMIAGE à l’EMSI à la recherche d’un stage\\nPFE à partir du mois de mars \\nAnglais : niveau c1\\nFrançais : niveau c1\\nArabe : langue maternelleWail Benharrats\\n07/2023-08/2023 - Stage de fin d’année\\nEntreprise ECONOCOM\\nApplication Web de Gestion des Congés\\n07/2024-08/2024 - Stage de de fin d’année\\nEntreprise DIRHAM EXPRESS\\nApplication Web de Gestion des employés et stocksOctobre 2024  \\n Master MIAGE IA2 Université Côte d’Azure\\n2020-2025\\n Diplôme d'ingénieur en informatique et réseaux \\n École Marocaine des Sciences de l'Ingénieur\\n2019-2020\\nBac Sciences Physiques\\nLycée scientifique Tour Hassan\\nLangages de Programmation : C,C++, Java, Python, C#\\nFrameworks : Django,Fast API,.NET,Spring Boot,JEE\\nBases de Données : SQL, T-SQL, PL/SQL, MySQL Server,\\nOracle\\nOutils ETL : Talend Open Studio\\nBig Data : Hadoop MapReduce,Pig,Hive, Microsoft Azure\\nConception et Modélisation : Merise, UML\\nDéveloppement Mobile : Android StudioProjet Fin d’année de la 4eme année\\nRéalisation d’une application web\\nd’archivage en utilisant Spring Boot\\nProjet Fin d’année de la 3eme année\\nRéalisation d’une application web de\\ngestion d'école en utilisant Django\\nCentre d’intérêts\\nSport\\nSuivi des tendances technologiques\\nbénévolat\"]\nExpériences: []\nCompétences: []\nLangues: []\n\n--------------------------------------------------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"     filename                                         formations experiences  \\\n0  cvwail.pdf  [Expérience professionnelleCONTACT\\nConception...          []   \n\n  competences langues  \n0          []      []  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>formations</th>\n      <th>experiences</th>\n      <th>competences</th>\n      <th>langues</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cvwail.pdf</td>\n      <td>[Expérience professionnelleCONTACT\\nConception...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<h2>Analyse détaillée des CV</h2><h3>CV: cvwail.pdf</h3><table border='1' width='100%'><tr><th>Catégorie</th><th>Détails</th></tr><tr><td style='width:20%; font-weight:bold; vertical-align:top;'>Formations</td><td><ul><li>Expérience professionnelleCONTACT\nConception et développement complet d'une application web de\ngestion des congés utilisant FastAPI, un framework Python pour\nles API web.\nDéveloppement des fonctionnalités de gestion des demandes\nde congés, de suivi des congés disponibles, et de génération de\nrapports pour les employés et les managers.\nConception et développement complet d'une application web de\ngestion des employés et stocks en utilisant Django et en intégrant\ndans le projet la reconnaissance faciale et les détection des objets .\nConnaissances techniques Projets academiquesformation Academique\nCertifications\nOracle Database Administration I\n(2024)\ningénierie logicielle (2023)\n Modélisation des systèmes \n logiciels a l’aide de l’UML\nPython for everybody - University of\nMichigan (2023)\nReact Basics (2023)\nUnix System Basics (2023)\nLangues0661990707\nbenharatswail@gmail.com\nRabat, MarocWAIL BENHARRATS\nFutur ingénieur en informatique option\nMIAGE à l’EMSI à la recherche d’un stage\nPFE à partir du mois de mars \nAnglais : niveau c1\nFrançais : niveau c1\nArabe : langue maternelleWail Benharrats\n07/2023-08/2023 - Stage de fin d’année\nEntreprise ECONOCOM\nApplication Web de Gestion des Congés\n07/2024-08/2024 - Stage de de fin d’année\nEntreprise DIRHAM EXPRESS\nApplication Web de Gestion des employés et stocksOctobre 2024  \n Master MIAGE IA2 Université Côte d’Azure\n2020-2025\n Diplôme d'ingénieur en informatique et réseaux \n École Marocaine des Sciences de l'Ingénieur\n2019-2020\nBac Sciences Physiques\nLycée scientifique Tour Hassan\nLangages de Programmation : C,C++, Java, Python, C#\nFrameworks : Django,Fast API,.NET,Spring Boot,JEE\nBases de Données : SQL, T-SQL, PL/SQL, MySQL Server,\nOracle\nOutils ETL : Talend Open Studio\nBig Data : Hadoop MapReduce,Pig,Hive, Microsoft Azure\nConception et Modélisation : Merise, UML\nDéveloppement Mobile : Android StudioProjet Fin d’année de la 4eme année\nRéalisation d’une application web\nd’archivage en utilisant Spring Boot\nProjet Fin d’année de la 3eme année\nRéalisation d’une application web de\ngestion d'école en utilisant Django\nCentre d’intérêts\nSport\nSuivi des tendances technologiques\nbénévolat</li></ul></td></tr><tr><td style='font-weight:bold; vertical-align:top;'>Expériences</td><td>Non disponible</td></tr><tr><td style='font-weight:bold; vertical-align:top;'>Compétences</td><td>Non disponible</td></tr><tr><td style='font-weight:bold; vertical-align:top;'>Langues</td><td>Non disponible</td></tr></table><br><hr><br>"},"metadata":{}},{"name":"stdout","text":"Statistiques sur les CV analysés:\nNombre total de CV: 1\nNombre moyen d'expériences professionnelles par CV: 0.00\nNombre moyen de formations par CV: 1.00\nNombre moyen de compétences par CV: 0.00\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Installer les bibliothèques nécessaires\n!pip install PyPDF2\n!pip install requests\n!pip install pandas\n!pip install -U google-generativeai  # Mettre à jour à la dernière version\n\n# Importer les bibliothèques\nimport PyPDF2\nimport requests\nimport json\nimport pandas as pd\nimport os\nfrom IPython.display import display, HTML\nimport google.generativeai as genai\n\n# Configurer l'API key pour Gemini\ngemini_api_key = \"AIzaSyD_TbpEKWfOM5bnzfON8UjtTfrffwu29HQ\"  # Remplacez par votre clé API Gemini\ngenai.configure(api_key=gemini_api_key)\n\n# Fonction pour extraire le texte du PDF\ndef extract_text_from_pdf(pdf_path):\n    with open(pdf_path, \"rb\") as file:\n        reader = PyPDF2.PdfReader(file)\n        text = \"\"\n        for page in reader.pages:\n            text += page.extract_text()\n    return text\n\n# Fonction pour analyser le CV avec l'API Gemini\ndef analyze_cv_with_gemini(cv_text):\n    try:\n        # Obtenir la liste des modèles disponibles\n        models = genai.list_models()\n        # Afficher les modèles disponibles pour le débogage\n        print(\"Modèles disponibles:\")\n        for model in models:\n            print(f\"- {model.name}\")\n        \n        # Sélectionner le premier modèle de type text\n        gemini_model = None\n        for model in models:\n            if \"gemini\" in model.name.lower() and \"generateContent\" in [m.name for m in model.supported_methods]:\n                gemini_model = model.name\n                print(f\"Utilisation du modèle: {gemini_model}\")\n                break\n        \n        if not gemini_model:\n            # Fallback sur un nom courant si aucun modèle n'a été trouvé\n            gemini_model = \"models/gemini-1.5-pro\"\n            print(f\"Aucun modèle trouvé, tentative avec: {gemini_model}\")\n        \n        # Créer le modèle Gemini\n        model = genai.GenerativeModel(gemini_model)\n        \n        # Créer un prompt pour extraire les informations du CV\n        prompt = f\"\"\"\n        Analyse le CV suivant et extrait ces informations exactes au format JSON:\n        1. formations: liste des formations (diplômes, établissements, dates)\n        2. experiences: liste des expériences professionnelles (postes, entreprises, dates, descriptions)\n        3. competences: liste des compétences techniques et non-techniques\n        4. langues: liste des langues maîtrisées avec leur niveau\n\n        CV:\n        {cv_text}\n\n        Réponds uniquement avec un objet JSON valide contenant ces 4 catégories sans texte supplémentaire.\n        \"\"\"\n        \n        # Appeler l'API Gemini\n        response = model.generate_content(prompt)\n        \n        # Extraire et parser la réponse JSON\n        response_text = response.text\n        # Trouver et extraire le JSON (entre accolades)\n        start_idx = response_text.find('{')\n        end_idx = response_text.rfind('}') + 1\n        \n        if start_idx != -1 and end_idx != -1:\n            json_str = response_text[start_idx:end_idx]\n            return json.loads(json_str)\n        else:\n            # Si on ne trouve pas de JSON, on retourne la réponse brute\n            return {\"error\": \"Pas de JSON trouvé dans la réponse\", \"raw_response\": response_text}\n    except Exception as e:\n        return {\"error\": str(e), \"raw_response\": str(e)}\n\n# Exemple d'utilisation\ncv_folder = \"/kaggle/input/cvvvvvvvvvv\"  # Chemin vers votre dossier de CVs\nresults = []\n\n# Analyser les CV\nfor filename in os.listdir(cv_folder):  # Traitez tous les fichiers\n    if filename.endswith(\".pdf\"):\n        pdf_path = os.path.join(cv_folder, filename)\n        print(f\"Traitement du fichier: {filename}\")\n        \n        cv_text = extract_text_from_pdf(pdf_path)\n        cv_data = analyze_cv_with_gemini(cv_text)\n        \n        # Extraire le contenu réel du JSON de la réponse de l'API\n        try:\n            # Vérifier si une erreur est survenue\n            if \"error\" in cv_data:\n                print(f\"Erreur lors de l'analyse de {filename}: {cv_data['error']}\")\n                continue\n            \n            # Afficher les informations structurées\n            print(f\"\\n--- Résultats pour {filename} ---\")\n            print(f\"Formations: {cv_data.get('formations', 'Non disponible')}\")\n            print(f\"Expériences: {cv_data.get('experiences', 'Non disponible')}\")\n            print(f\"Compétences: {cv_data.get('competences', 'Non disponible')}\")\n            print(f\"Langues: {cv_data.get('langues', 'Non disponible')}\")\n            print(\"\\n\" + \"-\"*50 + \"\\n\")\n            \n            results.append({\n                \"filename\": filename,\n                \"formations\": cv_data.get('formations', []),\n                \"experiences\": cv_data.get('experiences', []),\n                \"competences\": cv_data.get('competences', []),\n                \"langues\": cv_data.get('langues', [])\n            })\n        except Exception as e:\n            print(f\"Erreur lors du traitement de {filename}: {e}\")\n            print(f\"Réponse brute: {cv_data}\")\n\n# Créer un DataFrame pour une visualisation plus structurée\nif results:\n    # Création d'un DataFrame pour une vue d'ensemble\n    df = pd.DataFrame(results)\n    display(df)\n    \n    # Création d'une visualisation HTML plus détaillée\n    html_output = \"<h2>Analyse détaillée des CV</h2>\"\n    for result in results:\n        html_output += f\"<h3>CV: {result['filename']}</h3>\"\n        html_output += \"<table border='1' width='100%'>\"\n        html_output += \"<tr><th>Catégorie</th><th>Détails</th></tr>\"\n        \n        # Formations\n        html_output += \"<tr><td style='width:20%; font-weight:bold; vertical-align:top;'>Formations</td><td>\"\n        if result['formations']:\n            html_output += \"<ul>\"\n            for item in result['formations']:\n                html_output += f\"<li>{item}</li>\"\n            html_output += \"</ul>\"\n        else:\n            html_output += \"Non disponible\"\n        html_output += \"</td></tr>\"\n        \n        # Expériences\n        html_output += \"<tr><td style='font-weight:bold; vertical-align:top;'>Expériences</td><td>\"\n        if result['experiences']:\n            html_output += \"<ul>\"\n            for item in result['experiences']:\n                html_output += f\"<li>{item}</li>\"\n            html_output += \"</ul>\"\n        else:\n            html_output += \"Non disponible\"\n        html_output += \"</td></tr>\"\n        \n        # Compétences\n        html_output += \"<tr><td style='font-weight:bold; vertical-align:top;'>Compétences</td><td>\"\n        if result['competences']:\n            html_output += \"<ul>\"\n            for item in result['competences']:\n                html_output += f\"<li>{item}</li>\"\n            html_output += \"</ul>\"\n        else:\n            html_output += \"Non disponible\"\n        html_output += \"</td></tr>\"\n        \n        # Langues\n        html_output += \"<tr><td style='font-weight:bold; vertical-align:top;'>Langues</td><td>\"\n        if result['langues']:\n            html_output += \"<ul>\"\n            for item in result['langues']:\n                html_output += f\"<li>{item}</li>\"\n            html_output += \"</ul>\"\n        else:\n            html_output += \"Non disponible\"\n        html_output += \"</td></tr>\"\n        \n        html_output += \"</table><br><hr><br>\"\n    \n    # Affichage du tableau HTML\n    display(HTML(html_output))\n    \n    # Générer quelques statistiques\n    print(\"Statistiques sur les CV analysés:\")\n    print(f\"Nombre total de CV: {len(results)}\")\n    \n    # Calculer le nombre moyen d'expériences par CV\n    avg_exp = sum(len(r['experiences']) for r in results) / len(results) if results else 0\n    print(f\"Nombre moyen d'expériences professionnelles par CV: {avg_exp:.2f}\")\n    \n    # Calculer le nombre moyen de formations par CV\n    avg_form = sum(len(r['formations']) for r in results) / len(results) if results else 0\n    print(f\"Nombre moyen de formations par CV: {avg_form:.2f}\")\n    \n    # Calculer le nombre moyen de compétences par CV\n    avg_comp = sum(len(r['competences']) for r in results) / len(results) if results else 0\n    print(f\"Nombre moyen de compétences par CV: {avg_comp:.2f}\")\nelse:\n    print(\"Aucun CV n'a pu être analysé. Vérifiez le chemin du dossier et le format des fichiers.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T00:20:05.116413Z","iopub.execute_input":"2025-03-21T00:20:05.116743Z","iopub.status.idle":"2025-03-21T00:20:47.223840Z","shell.execute_reply.started":"2025-03-21T00:20:05.116716Z","shell.execute_reply":"2025-03-21T00:20:47.222314Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2025.1.31)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\nRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.4->pandas) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.22.4->pandas) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.22.4->pandas) (2024.2.0)\nRequirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.8.3)\nCollecting google-generativeai\n  Downloading google_generativeai-0.8.4-py3-none-any.whl.metadata (4.2 kB)\nCollecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (1.34.1)\nRequirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.155.0)\nRequirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\nRequirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.11.0a2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.67.1)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.12.2)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.25.0)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.66.0)\nRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (2.32.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\nRequirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (2.29.0)\nRequirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.68.1)\nRequirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.48.2)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\nDownloading google_generativeai-0.8.4-py3-none-any.whl (175 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: google-ai-generativelanguage, google-generativeai\n  Attempting uninstall: google-ai-generativelanguage\n    Found existing installation: google-ai-generativelanguage 0.6.10\n    Uninstalling google-ai-generativelanguage-0.6.10:\n      Successfully uninstalled google-ai-generativelanguage-0.6.10\n  Attempting uninstall: google-generativeai\n    Found existing installation: google-generativeai 0.8.3\n    Uninstalling google-generativeai-0.8.3:\n      Successfully uninstalled google-generativeai-0.8.3\nSuccessfully installed google-ai-generativelanguage-0.6.15 google-generativeai-0.8.4\nTraitement du fichier: cvwail.pdf\nModèles disponibles:\n- models/chat-bison-001\n- models/text-bison-001\n- models/embedding-gecko-001\n- models/gemini-1.0-pro-vision-latest\n- models/gemini-pro-vision\n- models/gemini-1.5-pro-latest\n- models/gemini-1.5-pro-001\n- models/gemini-1.5-pro-002\n- models/gemini-1.5-pro\n- models/gemini-1.5-flash-latest\n- models/gemini-1.5-flash-001\n- models/gemini-1.5-flash-001-tuning\n- models/gemini-1.5-flash\n- models/gemini-1.5-flash-002\n- models/gemini-1.5-flash-8b\n- models/gemini-1.5-flash-8b-001\n- models/gemini-1.5-flash-8b-latest\n- models/gemini-1.5-flash-8b-exp-0827\n- models/gemini-1.5-flash-8b-exp-0924\n- models/gemini-2.0-flash-exp\n- models/gemini-2.0-flash\n- models/gemini-2.0-flash-001\n- models/gemini-2.0-flash-exp-image-generation\n- models/gemini-2.0-flash-lite-001\n- models/gemini-2.0-flash-lite\n- models/gemini-2.0-flash-lite-preview-02-05\n- models/gemini-2.0-flash-lite-preview\n- models/gemini-2.0-pro-exp\n- models/gemini-2.0-pro-exp-02-05\n- models/gemini-exp-1206\n- models/gemini-2.0-flash-thinking-exp-01-21\n- models/gemini-2.0-flash-thinking-exp\n- models/gemini-2.0-flash-thinking-exp-1219\n- models/learnlm-1.5-pro-experimental\n- models/gemma-3-27b-it\n- models/embedding-001\n- models/text-embedding-004\n- models/gemini-embedding-exp-03-07\n- models/gemini-embedding-exp\n- models/aqa\n- models/imagen-3.0-generate-002\nAucun modèle trouvé, tentative avec: models/gemini-1.5-pro\n\n--- Résultats pour cvwail.pdf ---\nFormations: [{'diplome': 'Master MIAGE IA2', 'etablissement': 'Université Côte d’Azure', 'dates': 'Octobre 2024'}, {'diplome': \"Diplôme d'ingénieur en informatique et réseaux\", 'etablissement': \"École Marocaine des Sciences de l'Ingénieur\", 'dates': '2020-2025'}, {'diplome': 'Bac Sciences Physiques', 'etablissement': 'Lycée scientifique Tour Hassan', 'dates': '2019-2020'}, {'diplome': 'Oracle Database Administration I', 'etablissement': None, 'dates': '2024'}, {'diplome': 'ingénierie logicielle', 'etablissement': None, 'dates': '2023'}, {'diplome': 'Python for everybody', 'etablissement': 'University of Michigan', 'dates': '2023'}, {'diplome': 'React Basics', 'etablissement': None, 'dates': '2023'}, {'diplome': 'Unix System Basics', 'etablissement': None, 'dates': '2023'}]\nExpériences: [{'poste': 'Stage de fin d’année', 'entreprise': 'ECONOCOM', 'dates': '07/2023-08/2023', 'description': 'Application Web de Gestion des Congés'}, {'poste': 'Stage de fin d’année', 'entreprise': 'DIRHAM EXPRESS', 'dates': '07/2024-08/2024', 'description': 'Application Web de Gestion des employés et stocks'}]\nCompétences: ['Langages de Programmation : C, C++, Java, Python, C#', 'Frameworks : Django, Fast API, .NET, Spring Boot, JEE', 'Bases de Données : SQL, T-SQL, PL/SQL, MySQL Server, Oracle', 'Outils ETL : Talend Open Studio', 'Big Data : Hadoop MapReduce, Pig, Hive, Microsoft Azure', 'Conception et Modélisation : Merise, UML', 'Développement Mobile : Android Studio', 'Modélisation des systèmes logiciels a l’aide de l’UML']\nLangues: [{'langue': 'Anglais', 'niveau': 'C1'}, {'langue': 'Français', 'niveau': 'C1'}, {'langue': 'Arabe', 'niveau': 'langue maternelle'}]\n\n--------------------------------------------------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"     filename                                         formations  \\\n0  cvwail.pdf  [{'diplome': 'Master MIAGE IA2', 'etablissemen...   \n\n                                         experiences  \\\n0  [{'poste': 'Stage de fin d’année', 'entreprise...   \n\n                                         competences  \\\n0  [Langages de Programmation : C, C++, Java, Pyt...   \n\n                                             langues  \n0  [{'langue': 'Anglais', 'niveau': 'C1'}, {'lang...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>formations</th>\n      <th>experiences</th>\n      <th>competences</th>\n      <th>langues</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cvwail.pdf</td>\n      <td>[{'diplome': 'Master MIAGE IA2', 'etablissemen...</td>\n      <td>[{'poste': 'Stage de fin d’année', 'entreprise...</td>\n      <td>[Langages de Programmation : C, C++, Java, Pyt...</td>\n      <td>[{'langue': 'Anglais', 'niveau': 'C1'}, {'lang...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<h2>Analyse détaillée des CV</h2><h3>CV: cvwail.pdf</h3><table border='1' width='100%'><tr><th>Catégorie</th><th>Détails</th></tr><tr><td style='width:20%; font-weight:bold; vertical-align:top;'>Formations</td><td><ul><li>{'diplome': 'Master MIAGE IA2', 'etablissement': 'Université Côte d’Azure', 'dates': 'Octobre 2024'}</li><li>{'diplome': \"Diplôme d'ingénieur en informatique et réseaux\", 'etablissement': \"École Marocaine des Sciences de l'Ingénieur\", 'dates': '2020-2025'}</li><li>{'diplome': 'Bac Sciences Physiques', 'etablissement': 'Lycée scientifique Tour Hassan', 'dates': '2019-2020'}</li><li>{'diplome': 'Oracle Database Administration I', 'etablissement': None, 'dates': '2024'}</li><li>{'diplome': 'ingénierie logicielle', 'etablissement': None, 'dates': '2023'}</li><li>{'diplome': 'Python for everybody', 'etablissement': 'University of Michigan', 'dates': '2023'}</li><li>{'diplome': 'React Basics', 'etablissement': None, 'dates': '2023'}</li><li>{'diplome': 'Unix System Basics', 'etablissement': None, 'dates': '2023'}</li></ul></td></tr><tr><td style='font-weight:bold; vertical-align:top;'>Expériences</td><td><ul><li>{'poste': 'Stage de fin d’année', 'entreprise': 'ECONOCOM', 'dates': '07/2023-08/2023', 'description': 'Application Web de Gestion des Congés'}</li><li>{'poste': 'Stage de fin d’année', 'entreprise': 'DIRHAM EXPRESS', 'dates': '07/2024-08/2024', 'description': 'Application Web de Gestion des employés et stocks'}</li></ul></td></tr><tr><td style='font-weight:bold; vertical-align:top;'>Compétences</td><td><ul><li>Langages de Programmation : C, C++, Java, Python, C#</li><li>Frameworks : Django, Fast API, .NET, Spring Boot, JEE</li><li>Bases de Données : SQL, T-SQL, PL/SQL, MySQL Server, Oracle</li><li>Outils ETL : Talend Open Studio</li><li>Big Data : Hadoop MapReduce, Pig, Hive, Microsoft Azure</li><li>Conception et Modélisation : Merise, UML</li><li>Développement Mobile : Android Studio</li><li>Modélisation des systèmes logiciels a l’aide de l’UML</li></ul></td></tr><tr><td style='font-weight:bold; vertical-align:top;'>Langues</td><td><ul><li>{'langue': 'Anglais', 'niveau': 'C1'}</li><li>{'langue': 'Français', 'niveau': 'C1'}</li><li>{'langue': 'Arabe', 'niveau': 'langue maternelle'}</li></ul></td></tr></table><br><hr><br>"},"metadata":{}},{"name":"stdout","text":"Statistiques sur les CV analysés:\nNombre total de CV: 1\nNombre moyen d'expériences professionnelles par CV: 2.00\nNombre moyen de formations par CV: 8.00\nNombre moyen de compétences par CV: 8.00\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"!pip install pymupdf google-generativeai\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T00:02:00.613356Z","iopub.execute_input":"2025-03-21T00:02:00.613673Z","iopub.status.idle":"2025-03-21T00:02:05.877032Z","shell.execute_reply.started":"2025-03-21T00:02:00.613646Z","shell.execute_reply":"2025-03-21T00:02:05.876048Z"}},"outputs":[{"name":"stdout","text":"Collecting pymupdf\n  Downloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\nRequirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.8.3)\nRequirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.6.10)\nRequirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (1.34.1)\nRequirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.155.0)\nRequirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\nRequirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.11.0a2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.67.1)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.12.2)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai) (1.25.0)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.66.0)\nRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (2.32.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\nRequirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (2.29.0)\nRequirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.68.1)\nRequirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.48.2)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\nDownloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pymupdf\nSuccessfully installed pymupdf-1.25.4\n","output_type":"stream"}],"execution_count":7}]}